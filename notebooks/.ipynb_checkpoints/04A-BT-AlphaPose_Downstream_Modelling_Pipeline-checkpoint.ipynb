{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKZ0B3ple07u"
      },
      "source": [
        "# AlphaPose and Downstream Modelling Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4lluUPesXr"
      },
      "source": [
        "This notebook contains the entire pipeline for extracting pose features from a given video, along with applying all of our downstream models on those extracted pose features.\n",
        "\n",
        "It represents the combination of all of our models, which can then be used to make predictions on new scenes and provide these to the API & Dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnGgEGbDfrwV"
      },
      "source": [
        "**Required TO-DO:**\n",
        "- Everyone needs to integrate their downstream model(s) into this pipeline, through defining helper functions for preprocessing, prediction, and post-processing to give the outputs needed for the dashboard (see below code for instructions).\n",
        "- Once done, this will give us a pipeline that can be run on either CPU or GPU as required! üëç üëç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdyG23fXTtCW"
      },
      "source": [
        "##¬†1. Installation of dependencies / Importing packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrl7BowWt1Id"
      },
      "source": [
        "Install MXNet and Gluoncv libraries. If GPU is in use, also install mxnet-cu101 (requires runtime restart after):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mxnet\n",
        "! pip install gluoncv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dkn5ZEDDKVQJ",
        "outputId": "168ae195-46fd-4a95-95fc-eb568b59b08c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Collecting gluoncv\n",
            "  Downloading gluoncv-0.10.5-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 17.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.63.0)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Installing collected packages: yacs, portalocker, autocfg, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.5 portalocker-2.4.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVc6wP-1U-e3",
        "outputId": "cf48da33-ac03-4ee0-aee0-cba04fdef93d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.0` and `torch==1.10.0+cu111` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mxnet as mx\n",
        "import gluoncv\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import skimage.io\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from collections import deque\n",
        "\n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.data.transforms.pose import detector_to_alpha_pose, heatmap_to_coord\n",
        "from gluoncv.utils.viz import cv_plot_image, cv_plot_keypoints, plot_image, cv_plot_bbox\n",
        "from gluoncv import utils\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fXntWpec24pY"
      },
      "outputs": [],
      "source": [
        "sns.set_style('white')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bihgjxyFUUna"
      },
      "source": [
        "## 2. Setting up models, data and directories:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKkTajJnUZZQ"
      },
      "source": [
        "### 2.1 Image Classification Model Loading and Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuGrh3idJjU"
      },
      "source": [
        "**Note:** In order to get this working, you need to make sure you've got all of the files from the github repo, including the model and clf_model directory within that. This contains the pre-trained image classification model that is required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DrU99QhQ24pa"
      },
      "outputs": [],
      "source": [
        "# get project path and other key directories for project\n",
        "PROJECT_PATH = os.sep.join(os.getcwd().split(os.sep)[:-1])\n",
        "DATA_DIR = os.path.join(PROJECT_PATH, 'data')\n",
        "\n",
        "# set path to test videos to use in this notebook\n",
        "TEST_VIDEO_DIR = os.path.join(DATA_DIR, 'test_videos')\n",
        "\n",
        "# define our model directory to obtain models as needed\n",
        "MODEL_DIR = os.path.join(PROJECT_PATH, 'models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDwMfOpBUNjb"
      },
      "source": [
        "Load pre-trained BiT model for mask classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "slQvqeKdiEFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "35f28700-7f76-4212-8c4f-49d39dbbc482"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-917b0566e462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# if not already done, load existing trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrained_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hub_module_v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(handle, tags, load_options)\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Expected before TF2.4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m     90\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected a string, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   is_hub_module_v1 = tf.io.gfile.exists(\n\u001b[1;32m     94\u001b[0m       native_module.get_module_proto_path(module_path))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mrepresenting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mModule\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s does not exist.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: models/mask_clf_model does not exist."
          ]
        }
      ],
      "source": [
        "# define folder that contains our trained model\n",
        "saved_model_dir = os.path.join(MODEL_DIR, 'mask_clf_model')\n",
        "\n",
        "# if not already done, load existing trained model\n",
        "trained_module = hub.KerasLayer(saved_model_dir, trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained FCNN model for behavior analysis:"
      ],
      "metadata": {
        "id": "U1hSfYv64zCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load bahavior analysis model\n",
        "behavior_analysis_model_dir = os.path.join(MODEL_DIR, 'pose_ana_model', 'four_behavior.h5')\n",
        "behavior_analysis_model = tf.keras.models.load_model(behavior_analysis_model_dir)\n",
        "# behavior_analysis_model = tf.keras.models.load_model('four_behavior.h5')"
      ],
      "metadata": {
        "id": "r3vXaYJ2468-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define behavior map dictionary"
      ],
      "metadata": {
        "id": "YXuh5mFtkQXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BEH_DIC={1:\"Standing\",2:\"Sittting\",3:\"Walking\",4:\"Lying Down\"}"
      ],
      "metadata": {
        "id": "aup13-kqkYFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tbemd6yUFWa"
      },
      "source": [
        "Set up main environment variables for the above mask classification model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6dp5rzl4UMIb"
      },
      "outputs": [],
      "source": [
        "# if images are generally small (smaller than 96 x 96 on avg)\n",
        "IMG_SIZE = (160, 160)\n",
        "RESIZE_TO = 128\n",
        "BATCH_SIZE = 32\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "# class id map for our mask model predictions\n",
        "CLASS_ID_MAP = { 0 : 'No Mask',\n",
        "                 1 : 'Mask'}\n",
        "\n",
        "# color map dictionary for different classes\n",
        "COLOR_MAP = {0 : [255.0, 0.0, 0.0],\n",
        "             1 : [0.0, 255.0, 0.0]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZI5uir6UdEY"
      },
      "source": [
        "### 2.2 AlphaPose Model Loading and Initialisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5o8xF2tUogF"
      },
      "source": [
        "Load and initialise our AlphaPose model (select CPU or GPU as required!):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAsmOm2TUnh7",
        "outputId": "ea58f496-e218-4341-dbee-a8df7e4db5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/models/yolo3_darknet53_coco-09767802.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/yolo3_darknet53_coco-09767802.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 224190/224190 [00:05<00:00, 44294.71KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/models/alpha_pose_resnet101_v1b_coco-de56b871.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/alpha_pose_resnet101_v1b_coco-de56b871.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "216179KB [00:04, 43894.88KB/s]                            \n"
          ]
        }
      ],
      "source": [
        "# initialise our alphapose model - either cpu or gpu subject to architecture\n",
        "ctx = mx.cpu()\n",
        "#ctx = mx.gpu()\n",
        "\n",
        "# load and initialise object detector that feeds into AlphaPose\n",
        "detector = get_model('yolo3_darknet53_coco', pretrained=True, ctx=ctx)\n",
        "\n",
        "# other object detection model options:\n",
        "# faster & smaller, but slight drop in performance\n",
        "#detector = get_model('yolo3_mobilenet1.0_coco', pretrained=True, ctx=ctx)\n",
        "\n",
        "# slightly faster, but worse performing option using single-shot-detector:\n",
        "#detector = get_model('ssd_512_mobilenet1.0_coco', pretrained=True, ctx=ctx)\n",
        "\n",
        "detector.reset_class(classes=['person'], reuse_weights={'person':'person'})\n",
        "detector.hybridize()\n",
        "\n",
        "# Load and initialise AlphaPose model (estimates poses from dectector outputs)\n",
        "estimator = get_model('alpha_pose_resnet101_v1b_coco', pretrained=True, ctx=ctx)\n",
        "estimator.hybridize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75HPdHBd3R0"
      },
      "source": [
        "We can now apply this AlphaPose model on a desired video / stream, by making predictions on each frame as it is received. We'll do this for an example video, as shown below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1TpqvyaU-LU"
      },
      "source": [
        "### 2.3 Configure test video / scenes location for running our script:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43i6zF0FZ7dC"
      },
      "source": [
        "Set path to .mp4 video to run pipeline on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JXTHXhPTaT5D"
      },
      "outputs": [],
      "source": [
        "# set filename and path for chosen test video for this notebook\n",
        "TEST_VIDEO_FILE = 'campus_1.mp4'\n",
        "TEST_VIDEO_FILEPATH = os.path.join(TEST_VIDEO_DIR, TEST_VIDEO_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGZCsEyZVK0r"
      },
      "source": [
        "## 3. Defining helper functions for all downstream models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq2Ff8N-eGie"
      },
      "source": [
        "Within this section we require helper functions that allow each of our downstream models to pre-process, make predictions and post-process predictions from the extracted pose features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsQox_mmVahs"
      },
      "source": [
        "### 3.1 Distance estimation helper **functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwtjH1pZViWV"
      },
      "source": [
        "[Define all helper functions needed for preprocessing pose features and computing the distance results needed for the dashboard here...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o80Mgygb24pf"
      },
      "outputs": [],
      "source": [
        "def to_3D(xf, yf, xh, yh, f, h=1.5):\n",
        "    \"\"\" Gives the 3D euclidian coordinates of a person (on feet position) given\n",
        "        its head and feet 2D coordinates in the image, the focal length of the\n",
        "        camera and the average  (with origin of 3D coordinates system projected\n",
        "        on the center of the 2D image, center of 2D coordinates system)\n",
        "\n",
        "    Args:\n",
        "        xf (float): abscissa of the feet position in the image\n",
        "        yf (float): ordinate of the feet position in the image\n",
        "        xh (float): abscissa of the head position in the image\n",
        "        yh (float): ordinate of the head position in the image\n",
        "        f (float): focal length of the camera\n",
        "        h (float): average nose-to-feet height of a person (default 1.5)\n",
        "                \n",
        "    Method:\n",
        "        Remove every error sensible operations or special cases, and do:\n",
        "        x = xh*h/((f*(1-xh/xf))**2 + ((yh*xf-xh*yf)/xf)**2)**0.5\n",
        "        H = x/xf*(f*(1-(x*(yh*xf-xh*yf)/(xh*xf*h))**2)**0.5\n",
        "            - x*yf*(yh*xf-xh*yf)/(xh*xf*h))\n",
        "        y = x*yf/xf/(1-(x*(yh*xf-xh*yf)/(xf*xh*h))**2)**0.5\n",
        "        theta = np.arccos(x*(yh*xf-xh*yf)/(xf*xh*h))\n",
        "    \n",
        "    Returns:\n",
        "        x (float): position of the person's feet along x-axis (axis located on the floor)\n",
        "        y (float): position of the person's feet along y-axis (axis located on the floor)\n",
        "        theta (float): angle of the camera from the ceiling, in rad\n",
        "        H (float): height of the camera\n",
        "    \"\"\"\n",
        "    # particular case, avoid division by 0 with simpler equations\n",
        "    if xf * xh == 0:\n",
        "        x = 0\n",
        "        temp1 = (yh - yf)/h\n",
        "\n",
        "        # case due to high error on the given coordinates\n",
        "        if abs(temp1) >= 1:\n",
        "            # fix values such as it can be removed later, in particular with H = -1\n",
        "            return 0, 0, 0, -1 \n",
        "        \n",
        "        temp2 = (1-temp1**2)**0.5\n",
        "        H = f*temp2 - yf*temp1\n",
        "        y = yf/temp2\n",
        "        theta = np.arccos(temp1)\n",
        "\n",
        "    else:\n",
        "        # case due to high error or if top view and person in (0, 0)\n",
        "        if xh == xf and yh == yf:\n",
        "            # fix values such as it can be removed later, in particular with H = -1\n",
        "            return 0, 0, 0, -1\n",
        "\n",
        "        x = xh*h/((f*(1-xh/xf))**2 + (yh-xh*yf/xf)**2)**0.5\n",
        "        temp1 = (yh/xh - yf/xf)/h\n",
        "\n",
        "        # case due to high error on the given coordinates\n",
        "        if abs(x*temp1) >= 1:\n",
        "            return 0, 0, 0, -1\n",
        "        \n",
        "        temp2 = (1-(x*temp1)**2)**0.5\n",
        "        H = x/xf*(f*temp2 - x*yf*temp1)\n",
        "        y = x*yf/(xf*temp2)\n",
        "        theta = np.arccos(x*temp1)\n",
        "        \n",
        "    return x, y, theta, H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8GkJF7V24pg"
      },
      "outputs": [],
      "source": [
        "def from_2D_to_3D(pose_feats, image_dim_x, image_dim_y, theta=None, H=None, f=None):\n",
        "    \"\"\" Gives the 3D euclidian coordinates of the persons in a image (on feet\n",
        "        position) given their heads and feet 2D coordinates in the image, and\n",
        "        the dimensions of the image (with origin of 3D coordinates system\n",
        "        projected on the center of the 2D image, center of 2D coordinates system)\n",
        "\n",
        "    Args:\n",
        "        image_keypoints (mxnet.nd.NDArray): 2D array containing x and y co-ords columns\n",
        "                                            for the 17 COCO keypoints (17 rows)\n",
        "        image_dim_x (float): width of the image\n",
        "        image_dim_y (float): height of the image\n",
        "        theta (float): angle of the camera from the ceiling, in rad (default None)\n",
        "        H (float): height of the camera\n",
        "        f (float): focal length of the camera (default None)\n",
        "\n",
        "    Returns:\n",
        "        X (numpy.ndarray): positions of the persons' feet along x-axis (axis located on the floor)\n",
        "        Y (numpy.ndarray): positions of the persons' feet along y-axis (axis located on the floor)\n",
        "        theta (float): angle of the camera from the ceiling, in rad (default None)\n",
        "        H (float): height of the camera (default None)\n",
        "        f (float): focal length of the camera (default None)\n",
        "    \"\"\"\n",
        "    image_keypoints = pose_feats.asnumpy()\n",
        "    n_persons = image_keypoints.shape[0]\n",
        "    eps = np.pi / 2 / 100\n",
        "    \n",
        "    # initialize some variables whether to determine theta or H\n",
        "    if theta:\n",
        "        theta_defined = True\n",
        "    else:\n",
        "        theta_defined = False\n",
        "    if H:\n",
        "        H_defined = True\n",
        "    else:\n",
        "        H_defined = False\n",
        "    \n",
        "    # translate the positions to the right 2D coordinate system\n",
        "    feet = np.zeros((n_persons, 2))\n",
        "    nose = np.zeros((n_persons, 2))\n",
        "    for index in range(n_persons):\n",
        "        # get keypoints of the person\n",
        "        p = image_keypoints[index]\n",
        "\n",
        "        # from img_array coordinates to 2D euclidian coordinates where origin is image center\n",
        "        feet[index] = ((p[-1, 0]+p[-2, 0])/2 - image_dim_x/2, \n",
        "                       image_dim_y/2 - (p[-1, 1]+p[-2, 1])/2)\n",
        "        \n",
        "        nose[index] = p[0, 0] - image_dim_x/2, image_dim_y/2 - p[0, 1]\n",
        "    \n",
        "    # determine f if not given (with trichotomy)\n",
        "    if not f:\n",
        "        # interval boundaries for trichotomy (here 30¬∞ < FOV < 120¬∞)\n",
        "        b = [image_dim_x / (2 * np.tan(120/180 * np.pi/2)), \n",
        "             image_dim_x / (2 * np.tan(30/180 * np.pi/2))]\n",
        "        # f = d_image / (2 * np.tan(FOV/180 * np.pi/2))\n",
        "\n",
        "        while b[1]-b[0] > np.mean(b) / 50: # maximum 1% error on value found\n",
        "\n",
        "            # trichotomy first third value\n",
        "            f_test = b[0]+(b[1]-b[0])/10\n",
        "            \n",
        "            # determine 3D positions, theta and H for each person\n",
        "            res = np.zeros((n_persons, 4))\n",
        "            for i in range(n_persons):\n",
        "                res[i] = to_3D(feet[i, 0], feet[i, 1], nose[i, 0], nose[i, 1], f_test)\n",
        "            \n",
        "            # remove wrong values\n",
        "            selected = (res[:, 3] > 1) * (res[:, 2] > eps) * (res[:, 2] < np.pi/2 - eps)\n",
        "            \"\"\"\n",
        "            if np.sum(selected) == 0:\n",
        "                selected = np.ones(n_persons, dtype=bool)\n",
        "            \"\"\"\n",
        "            # if not given, estimate theta and H: median to avoid outliers impact\n",
        "            if not theta_defined:\n",
        "                theta = np.median(res[selected, 2])\n",
        "            if not H_defined:\n",
        "                H = np.median(res[selected, 3])\n",
        "            \n",
        "            # calculate median error on positions: median to avoid outliers impact\n",
        "            temp = f_test*np.sin(theta) / (H + np.sin(theta)*np.cos(theta)*res[selected, 1])\n",
        "            r1 = np.median((temp*res[selected, 0] - feet[selected, 0])**2\n",
        "                            + (temp*res[selected, 1]*np.sin(theta) - feet[selected, 1])**2)\n",
        "\n",
        "            # trichotomy second third value\n",
        "            f_test = b[0]+9*(b[1]-b[0])/10\n",
        "            \n",
        "            # determine 3D positions, theta and H for each person\n",
        "            res = np.zeros((n_persons, 4))\n",
        "            for i in range(n_persons):\n",
        "                res[i] = to_3D(feet[i, 0], feet[i, 1], nose[i, 0], nose[i, 1], f_test)\n",
        "            \n",
        "            # remove wrong values\n",
        "            selected = (res[:, 3] > 1) * (res[:, 2] > eps) * (res[:, 2] < np.pi/2 - eps)\n",
        "            \"\"\"\n",
        "            if np.sum(selected) == 0:\n",
        "                selected = np.ones(n_persons, dtype=bool)\n",
        "            \"\"\"\n",
        "            # if not given, estimate theta and H: median to avoid outliers impact\n",
        "            if not theta_defined:\n",
        "                theta = np.median(res[selected, 2])\n",
        "            if not H_defined:\n",
        "                H = np.median(res[selected, 3])\n",
        "            \n",
        "            # calculate median error on positions: median to avoid outliers impact\n",
        "            temp = f_test*np.sin(theta) / (H + np.sin(theta)*np.cos(theta)*res[selected, 1])\n",
        "            r2 = np.median((temp*res[selected, 0] - feet[selected, 0])**2\n",
        "                            + (temp*res[selected, 1]*np.sin(theta) - feet[selected, 1])**2)\n",
        "            \n",
        "            # compare values and update the interval boundaries\n",
        "            if r1 > r2:\n",
        "                b[0] = b[0]+(b[1]-b[0])/10\n",
        "            else:\n",
        "                b[1] = b[0]+9*(b[1]-b[0])/10\n",
        "        \n",
        "        # finally take the center of interval as value found\n",
        "        f = np.mean(b)\n",
        "    \n",
        "    if not theta_defined or not H_defined:\n",
        "        # final iteration with found/given f value\n",
        "        res = np.zeros((n_persons, 4))\n",
        "        for i in range(n_persons):\n",
        "            res[i, :] = to_3D(feet[i, 0], feet[i, 1], nose[i, 0], nose[i, 1], f)\n",
        "\n",
        "        # remove wrong values\n",
        "        selected = (res[:, 3] > 1) * (res[:, 2] > eps) * (res[:, 2] < np.pi/2 - eps)\n",
        "        \n",
        "        if np.sum(selected) == 0:\n",
        "            selected = np.ones(n_persons, dtype=bool)\n",
        "        \n",
        "        print(f\"SELECTED: {selected}\")\n",
        "        \n",
        "        print(f\"res[selected] : {res[selected]}\")\n",
        "    \n",
        "        # If not given, estimate theta and H: use density to increase precision\n",
        "        if not theta_defined:\n",
        "            d_theta = np.median(res[selected, 2])\n",
        "            \n",
        "            ### ERROR / ISSUE #### \n",
        "            # - When res[selected, 2] has no elements following error is raised:\n",
        "            #     'ValueError: min() arg is an empty sequence'\n",
        "            \n",
        "            # TO-DO: We need to capture this edge-case error and correct / remedy it\n",
        "        \n",
        "            density_range_theta = np.linspace(min(res[selected, 2]), \n",
        "                                              max(res[selected, 2]), 200)\n",
        "        \n",
        "            kde_skl = KernelDensity(bandwidth=d_theta)\n",
        "            kde_skl.fit(res[selected, 2, np.newaxis])\n",
        "            log_pdf = kde_skl.score_samples(density_range_theta[:, np.newaxis])\n",
        "            density_theta = np.exp(log_pdf)\n",
        "            theta = density_range_theta[np.argmax(density_theta)]\n",
        "            \n",
        "        if not H_defined:\n",
        "            d_H = np.median(res[selected, 3])\n",
        "            \n",
        "            print(f\"d_H: {d_H}\")\n",
        "            \n",
        "            density_range_H = np.linspace(min(res[selected, 3]), max(res[selected, 3]), 200)\n",
        "            kde_skl = KernelDensity(bandwidth=d_H)\n",
        "            kde_skl.fit(res[selected, 3, np.newaxis])\n",
        "            log_pdf = kde_skl.score_samples(density_range_H[:, np.newaxis])\n",
        "            density_H = np.exp(log_pdf)\n",
        "            H = density_range_H[np.argmax(density_H)]\n",
        "    \n",
        "    # 3D positions (top view)\n",
        "    Y = H * feet[:, 1] / (f*np.sin(theta)**2 - feet[:, 1]*np.cos(theta)*np.sin(theta))\n",
        "    X = Y * feet[:, 0] * np.sin(theta) / feet[:, 1]\n",
        "    \n",
        "    return X, Y, theta, H, f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X8zPOxk24pi"
      },
      "outputs": [],
      "source": [
        "def get_respect_social_distancing(positions, social_distance=2):\n",
        "    \"\"\" Get social distancing labels (0 = no respect, 1 = respect)\n",
        "\n",
        "    Args:\n",
        "        positions (numpy.ndarray): positions of people\n",
        "        social_distance (float): social distancing treshold (default 2)\n",
        "    \n",
        "    Returns:\n",
        "        respect_social_distancing (numpy.ndarray): whether the persons repect social\n",
        "                                                   distancing (0 = no, 1 = yes)\n",
        "    \"\"\"\n",
        "    # compute the distance matrix then find wheter people are respecting\n",
        "    respect_social_distancing = (np.sum(\n",
        "        np.linalg.norm(\n",
        "            positions[:, None, :] - positions[None, :, :], axis=-1) \n",
        "        < social_distance, axis = 0) == 1).astype(int)\n",
        "\n",
        "    return respect_social_distancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCwboWme24pk"
      },
      "source": [
        "Helper function for plotting top-view of the scene (useful for confirming results / implementation is correct):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46uIicJ024pk"
      },
      "outputs": [],
      "source": [
        "def plot_top_view(positions, H, theta, f, image_dim_x, image_dim_y, figsize=(7,6)):\n",
        "    \"\"\" Helper function for plotting top-view of the scene for chosen images \n",
        "    \n",
        "    Args:\n",
        "        positions (numpy.ndarray): positions of people\n",
        "        H (float): camera height\n",
        "        theta (float): camera angle from ceiling, in rad\n",
        "        f (float): camera focal length\n",
        "        figsize (tuple): tuple of desired figure size to plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    # get observed area\n",
        "    limits = np.array([[-image_dim_x/2, -image_dim_y/2], [-image_dim_x/2, image_dim_y/2], [image_dim_x/2, image_dim_y/2], [image_dim_x/2, -image_dim_y/2], [-image_dim_x/2, -image_dim_y/2]])\n",
        "    limits_y = H * limits[:, 1] / (f*np.sin(theta)**2 - limits[:, 1]*np.cos(theta)*np.sin(theta))\n",
        "    limits_x = limits_y * limits[:, 0] * np.sin(theta) / limits[:, 1]\n",
        "    ax.plot(limits_x, limits_y, '--k', linewidth = 1, alpha = 0.5)            \n",
        "    \n",
        "    # get axis and limits\n",
        "    m_x, M_x, m_y, M_y = np.min(limits_x)*1.05, np.max(limits_x)*1.05, np.min(limits_y)*1.05, np.max(limits_y)*1.05\n",
        "    ax.plot([0, 0], [m_y, M_y], '-k', linewidth = 2, alpha = 0.2)\n",
        "    ax.plot([m_x, M_x], [0, 0], '-k', linewidth = 2, alpha = 0.2)\n",
        "\n",
        "    # plot positions of people\n",
        "    ax.scatter(positions[:, 0], positions[:, 1], c='red', marker='o', s=15)\n",
        "    \n",
        "    ax.set_xlim(m_x, M_x)\n",
        "    ax.set_ylim(m_y, M_y)\n",
        "    ax.set_aspect('equal')\n",
        "        \n",
        "    # hide our x and y-ticks on the axes\n",
        "    ax.axis('off')\n",
        "    \n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU3PnZ3sV3Md"
      },
      "source": [
        "### 3.2 Clustering helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxZjpWMx24pk"
      },
      "outputs": [],
      "source": [
        "def get_clusters(positions, treshold=1):\n",
        "    \"\"\" Get clusters information (number of clusters and persons' clusters labels)\n",
        "\n",
        "    Args:\n",
        "        positions (numpy.ndarray): positions of people\n",
        "        treshold (float): maximum distance separating a person from the closest person\n",
        "                          in the cluster (default 1)\n",
        "    \n",
        "    Returns:\n",
        "        persons_clusters (numpy.ndarray): clusters to which each person belongs\n",
        "    \"\"\"\n",
        "    # compute the clusters, where a cluster is made by persons less than a \n",
        "    # treshold distance from another one of the same cluster\n",
        "    clusters = DBSCAN(eps=treshold, min_samples=2).fit(positions)\n",
        "    persons_clusters = clusters.labels_\n",
        "    \n",
        "    return persons_clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fhXl5Wn24pk"
      },
      "source": [
        "Helper function for plotting clustering (useful for confirming results / implementation is correct):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt1Pfhwk24pl"
      },
      "outputs": [],
      "source": [
        "def plot_clusters(img, persons_clusters, bounding_boxs, figsize=(7,6)):\n",
        "    \"\"\" Helper function for plotting clusters for chosen images (black is no cluster)\n",
        "    \n",
        "    Args:\n",
        "        img (numpy.ndarray): original image array\n",
        "        persons_clusters (numpy.ndarray): clusters to which each person belongs\n",
        "        bounding_boxs (numpy.ndarray or mxnet.nd.NDArray): bounding boxes\n",
        "        figsize (tuple): tuple of desired figure size to plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "\n",
        "    if isinstance(bounding_boxs, mx.nd.NDArray):\n",
        "        bounding_boxs = bounding_boxs.asnumpy()\n",
        "\n",
        "    # bouding boxes colors\n",
        "    colors = np.array([[255, 0, 0], [0, 255, 0], [0, 0, 255],\n",
        "                      [255, 255, 0], [255, 0, 255], [0, 255, 255],\n",
        "                      [255, 255, 255], \n",
        "                      [127, 0, 0], [0, 127, 0], [0, 0, 127],\n",
        "                      [127, 127, 0], [127, 0, 127], [0, 127, 127],\n",
        "                      [127, 127, 127],\n",
        "                      [0, 0, 0]]) / 255\n",
        "\n",
        "    for i, box in enumerate(bounding_boxs):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "\n",
        "        # plot bbox in appropriate color\n",
        "        rect = mpatches.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, \n",
        "                                  linewidth=2, edgecolor=colors[persons_clusters[i]], \n",
        "                                  facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # hide our x and y-ticks on the axes\n",
        "    ax.axis('off')\n",
        "\n",
        "    ax.imshow(img)\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq1dA4QCVdrQ"
      },
      "source": [
        "### 3.3 Pose classification helper functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def behavior_analysis(pose_feats, bbox, model):\n",
        "    \"\"\"Using 34 cooradinate value of pose features and model to analyze behavior\n",
        "      TODO: 1.adding information of bounding box as input\n",
        "            2.adding behavior class, others, for other or unclear behaviors\n",
        "\n",
        "    Args:\n",
        "        pose_feats (mxnet array) : 2D array containing x and y co-ords\n",
        "                  columns for the 17 COCO keypoints (17 rows).\n",
        "        bbox (mxnet array) : 1D array containing bounding box information\n",
        "        model (tf.keras.models.Sequential()) : FCNN model for behavior analysis\n",
        "  \n",
        "    Return:\n",
        "        behavior_class (str) : name of behavior class, including standing, sitting, walking, and lying down\n",
        "        score (flost) : Score of classification results\n",
        "    \"\"\"\n",
        "    # Prepare data\n",
        "    pose_feats = pred_coords.asnumpy()\n",
        "    # Normalize data\n",
        "    result = (pose_feats[:, :, 0].T - bbox[:, 0]) / (bbox[:, 2] - bbox[:, 0])\n",
        "    pose_feats[:, :, 0] = result.T\n",
        "    result = (pose_feats[:, :, 1].T - bbox[:, 1]) / (bbox[:, 3] - bbox[:, 1])\n",
        "    pose_feats[:, :, 1] = result.T\n",
        "    pose_feats = pose_feats.reshape(pose_feats.shape[0], -1)\n",
        "    # predict class and get label and score\n",
        "    result = model.predict(pose_feats)\n",
        "    label = np.argmax(result, axis=1)\n",
        "    score = np.max(result, axis=1)\n",
        "    return label, score\n"
      ],
      "metadata": {
        "id": "FjQiGtXX84m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGMAhDwxVUQW"
      },
      "source": [
        "### 3.4 Image classification model helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldfVV3QMWA-K"
      },
      "source": [
        "Helper functions are defined below for doing the following:\n",
        "- Computing suitable head regions for all people in a scene using pose features\n",
        "- Obtaining numpy array of all head regions from a given image array\n",
        "- Obtaining a tensorflow tensor data object of the head regions, including preprocessing required for the classification model\n",
        "- Pre-trained classification model functions for predicting masks for given input tensor of head regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7mEkiUE0Pgj"
      },
      "outputs": [],
      "source": [
        "def compute_head_boxes(pose_feats, factor=1.1):\n",
        "    \"\"\" Obtain bounding box of heads using head average\n",
        "        co-ordinates and torso length as a rough guide. \n",
        "    \n",
        "    Args:\n",
        "        pose_feats (mxnet array) : 2D array containing x and y co-ords\n",
        "                columns for the 17 COCO keypoints (17 rows).\n",
        "        factor (float) : factor to multiply torso length by for the\n",
        "                        extracted head region (default 1.0)\n",
        "    Returns:\n",
        "        head_regions (np.array) : Array with head region box co-ordinates\n",
        "            in the form [x_mins, y_mins, w, h] for each person (row).\n",
        "    \"\"\"\n",
        "    # calculate the average head x and y coords\n",
        "    head_x_avgs = pose_feats[:,:5,0].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    head_y_avgs = pose_feats[:,:5,1].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    head_avgs = np.column_stack([head_x_avgs, head_y_avgs])\n",
        "    \n",
        "    # calculate left-ear to right-ear abs x dist as approx head width\n",
        "    head_widths = np.abs(pose_feats[:,4,0].asnumpy() - \n",
        "                         pose_feats[:,3,0].asnumpy()).reshape(-1, 1)\n",
        "    \n",
        "    # calculate average shoulder co-ordinates\n",
        "    shoulder_x_avgs = pose_feats[:,5:7,0].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    shoulder_y_avgs = pose_feats[:,5:7,1].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    shoulder_avgs = np.column_stack([shoulder_x_avgs, shoulder_y_avgs])\n",
        "\n",
        "    # calculate average waist (hip) co-ordinates\n",
        "    waist_x_avgs = pose_feats[:,11:13,0].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    waist_y_avgs = pose_feats[:,11:13,1].mean(axis=1).asnumpy().reshape(-1, 1)\n",
        "    waist_avgs = np.column_stack([waist_x_avgs, waist_y_avgs])\n",
        "    \n",
        "    # calculate torso length using obtained co-ordinates\n",
        "    torso_lengths = np.linalg.norm(shoulder_avgs - \n",
        "                    waist_avgs, axis=1).astype(int).reshape(-1, 1)\n",
        "    \n",
        "    # ensure torso length is at least 2x head_width - adjust otherwise\n",
        "    torso_lengths = np.maximum(torso_lengths, head_widths*2)\n",
        "    \n",
        "    # adjust torso lengths based on multiplier factor given\n",
        "    torso_lengths = (torso_lengths*factor).astype(int).reshape(-1, 1)\n",
        "    \n",
        "    # find head box xmins, ymins, widths and heights\n",
        "    x_mins = head_x_avgs - (torso_lengths / 2.0)\n",
        "    y_mins = head_y_avgs - (torso_lengths / 2.0)\n",
        "    w = torso_lengths.copy()\n",
        "    h = torso_lengths.copy()\n",
        "    \n",
        "    # ensure xmins and y mins are not below zero:\n",
        "    x_mins = np.maximum(x_mins, 0).astype(int)\n",
        "    y_mins = np.maximum(y_mins, 0).astype(int)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return np.column_stack([x_mins, y_mins, w, h])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb2c4ofP0nif"
      },
      "outputs": [],
      "source": [
        "def get_image_region_array(img_array, head_regions, \n",
        "                           normalise=True,\n",
        "                           reshape_size=(RESIZE_TO, RESIZE_TO)):\n",
        "    \"\"\" Helper function to gather head regions tensor.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame) : pandas dataframe with pose results.\n",
        "        img_name (str) : string containing exact name of image to plot.\n",
        "        image_dir (str) : string containing path to image directory.\n",
        "    \n",
        "    Returns:\n",
        "        tensor_stack (tf tensor) : tensor with resized image regions.\n",
        "    \"\"\"\n",
        "    \n",
        "    # get x max and y max of img to ensure we don't go out-of-bounds\n",
        "    y_max, x_max = img_array.shape[:2]\n",
        "    \n",
        "    # create a list of numpy arrays with our images\n",
        "    img_stack = [np.expand_dims(\n",
        "                    img_array[reg[1]: reg[1] + reg[3], \n",
        "                              reg[0]: reg[0] + reg[2]], axis=0) \n",
        "                 for reg in head_regions]\n",
        "\n",
        "    # convert list of np arrays into ragged tensor\n",
        "    tensor_stack = tf.ragged.constant(img_stack)\n",
        "\n",
        "    # resize all images within our ragged tensor\n",
        "    tensor_stack = tf.concat(\n",
        "        [tf.image.resize(tensor_stack[i].to_tensor(), reshape_size) \n",
        "         for i in tf.range(tensor_stack.nrows())], axis=0)\n",
        "    \n",
        "    if normalise:\n",
        "        tensor_stack = tensor_stack / 255.0\n",
        "    \n",
        "    return tensor_stack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHDq8qqOnEYv"
      },
      "outputs": [],
      "source": [
        "# define softmax layer to use for normalising logit outputs\n",
        "softmax_layer = tf.keras.layers.Softmax()\n",
        "\n",
        "def model_predict_probs(model, image_batch, softmax=True):\n",
        "    \"\"\" Helper function for making probability predictions \n",
        "        on an image batch \n",
        "\n",
        "    Args:\n",
        "        model (TFHub Model) : Trained model for making predictions.\n",
        "        image_batch (tf.tensor) : Tensor containing images for prediction.\n",
        "        softmax (bool) : Whether to apply softmax activation or not.\n",
        "    \n",
        "    Returns:\n",
        "        preds (np.array) : 2D output array of image predictions. First column \n",
        "                           is output for mask, second is for no_mask.\n",
        "    \"\"\"\n",
        "    preds = model(image_batch)\n",
        "    if softmax:\n",
        "        return softmax_layer(preds).numpy()\n",
        "    else:\n",
        "        return preds\n",
        "\n",
        "def get_prediction_labels(preds):\n",
        "    \"\"\" Get output prediction labels (0 = no_mask, 1 = mask) \"\"\"\n",
        "    return tf.argmax(preds, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6_FFmS4Xatz"
      },
      "source": [
        "Helper function for plotting image classification model predictions (useful for confirming results / implementation is correct):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfDtE1A6ipKH"
      },
      "outputs": [],
      "source": [
        "def plot_mask_predictions(img, labels, pred_probs, \n",
        "                          head_regions,\n",
        "                          color_map=COLOR_MAP, \n",
        "                          figsize=(7,6), \n",
        "                          legend=False,\n",
        "                          plot_proportion=True):\n",
        "    \"\"\" Helper function for plotting predictions for chosen images \n",
        "    \n",
        "    Args:\n",
        "        img (np.array) : Original image array.\n",
        "        labels (np.array) : Predicted class labels.\n",
        "        confidences (np.array) : Probabilities for predicted classes.\n",
        "        color_map (dict) : dictionary mapping class output labels.\n",
        "        figsize (tuple) : tuple of desired figure size to plot.\n",
        "        legend (bool) : Whether to show legend or not, default false.\n",
        "        box_col (str) : Column containing bbox regions to plot.\n",
        "    \"\"\"\n",
        "    # keep only first column as predicted confidence\n",
        "    confidences = list(pred_probs[:, 1])\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
        "    \n",
        "    # plot each bbox and annotate confidence\n",
        "    for i, box in enumerate(head_regions):\n",
        "        \n",
        "        # get co-ords for current bbox\n",
        "        x_min, y_min, w, h = box\n",
        "        \n",
        "        # if mask, annotate green\n",
        "        if labels[i] == 1:\n",
        "\n",
        "            # plot current predicted bbox in green\n",
        "            pred_rect = mpatches.Rectangle((x_min, y_min), w, h, \n",
        "                                        linewidth=2, edgecolor='g', \n",
        "                                        facecolor='none')\n",
        "\n",
        "            ax.text(x_min, y_min - 5, f\"{confidences[i]:.2f}\", \n",
        "                    bbox={\"facecolor\": \"tab:green\", \"alpha\": 0.4},\n",
        "                    clip_on=True)\n",
        "            \n",
        "        else:\n",
        "            # plot predicted non-mask in red\n",
        "            pred_rect = mpatches.Rectangle((x_min, y_min), w, h, \n",
        "                                        linewidth=2, edgecolor='r', \n",
        "                                        facecolor='none')\n",
        "        \n",
        "            ax.text(x_min, y_min - 5, f\"{1.0 - confidences[i]:.2f}\", \n",
        "                    bbox={\"facecolor\": \"tab:red\", \"alpha\": 0.4},\n",
        "                    clip_on=True)\n",
        "        \n",
        "        # add each bbox to plot\n",
        "        ax.add_patch(pred_rect)\n",
        "    \n",
        "    # if legend chosen, annotate what class is which color\n",
        "    if legend:\n",
        "        # map color map colors to matplotlib style colors\n",
        "        mpl_color_map = dict()\n",
        "        for object_name in color_map.keys():\n",
        "            mpl_color_map[object_name] = tuple([i/255 for i \n",
        "                                            in color_map[object_name]])\n",
        "    \n",
        "        # get object names and create legend lines for each class type\n",
        "        object_ids = list(color_map.keys())\n",
        "\n",
        "        object_names = [CLASS_ID_MAP[id] for id in object_ids]\n",
        "    \n",
        "        legend_lines = [Line2D([0],[0], \n",
        "                               color=mpl_color_map[object_ids[i]], \n",
        "                               lw=2) \n",
        "                        for i in range(len(object_ids))]\n",
        "        plt.legend(legend_lines, object_names, loc='best')\n",
        "    \n",
        "    # if plot proportion chosen, annotate mask % as title of fig\n",
        "    if plot_proportion:\n",
        "        # get mask proportion - No. of '1' labels out of total\n",
        "        mask_prop = np.array(np.bincount(labels)[1] / labels.shape[0])\n",
        "        plt.title(f\"Mask Proportion: {mask_prop * 100:.2f}%\", weight=\"bold\")\n",
        "    \n",
        "    # hide our x and y-ticks on the axes\n",
        "    ax.axis('off')\n",
        "\n",
        "    ax.imshow(img)\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJT73ngYX1R"
      },
      "source": [
        "## 4. Running AlphaPose on video example and obtaining all downstream modelling results:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8uflNPJZiSY"
      },
      "source": [
        "All of our downstream models can be run on the video frames as they are processed by our AlphaPose model.\n",
        "\n",
        "For each downstream model, we need to implement our modelling techniques (preprocessing, prediction & post-processing (if required)) after the AlphaPose model obtains pose extractions for each frame (see commented code below).\n",
        "\n",
        "This process will be done on our example video (as uploaded in section 2.3 above!):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgX8juxF24pn"
      },
      "source": [
        "Set basic variables for our results below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "P3Vn9LAh24pn"
      },
      "outputs": [],
      "source": [
        "# whether to plot results or not\n",
        "SHOW_POSES = False\n",
        "SHOW_MASK_PREDS = True\n",
        "\n",
        "# define how often to make predictions (2 times per second by default)\n",
        "MODELLING_FPS = 2\n",
        "\n",
        "# length to resize video short size in before detector\n",
        "VID_RESIZE_SHORT = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z3GsC2k24po"
      },
      "source": [
        "Run alphapose, with downstream models on video feed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9VQVK3ffVEtz"
      },
      "outputs": [],
      "source": [
        "# load uploaded video into opencv:\n",
        "cap = cv2.VideoCapture(TEST_VIDEO_FILEPATH)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# define how often to make predictions (2 times per second by default)\n",
        "MODELLING_FPS = 2\n",
        "\n",
        "# initially current frame is zero\n",
        "frame_count = 0\n",
        "\n",
        "# dictionary for scene-summary results (e.g. person counts, mask %)\n",
        "frame_results = {'image_id' : [],\n",
        "                 'person_count' : [],\n",
        "                 'clusters_count' : [],\n",
        "                 'social_distancing_compliance' : [],\n",
        "                 'mask_proportions' : []}\n",
        "\n",
        "# dictionary for per-person level results (bbox, keypoints, mask_on etc.)\n",
        "person_results = {'image_id' : [],\n",
        "                  'bbox' : [],\n",
        "                  'keypoints' : [],\n",
        "                  'confidences' : [],\n",
        "                  'position' : [],\n",
        "                  'in_cluster' : [],\n",
        "                  'respect_social_distancing' : [],\n",
        "                  'behavior' : [],\n",
        "                  'behavior_score' : [],\n",
        "                  'mask_preds' : [],\n",
        "                  'mask_pred_probs' : [],\n",
        "                  'mask_head_regions' : []}\n",
        "\n",
        "# parameters tracking\n",
        "time_step_average = 120\n",
        "theta_queue = deque()\n",
        "H_queue = deque()\n",
        "f_queue = deque()\n",
        "\n",
        "# whilst processing video, do the following loop..\n",
        "while(True):\n",
        "\n",
        "    # check video capture, and obtain current frame (image from video)\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # if our video is still being processed, do the following...\n",
        "    if(ret):\n",
        "\n",
        "        # preprocess frame as required for object detector & AlphaPose\n",
        "        frame = mx.nd.array(cv2.cvtColor(frame, \n",
        "                                         cv2.COLOR_BGR2RGB)).astype('uint8')\n",
        "        x, frame = gluoncv.data.transforms.presets.ssd.transform_test(frame, \n",
        "                                                        short=VID_RESIZE_SHORT)\n",
        "        x = x.as_in_context(ctx)\n",
        "\n",
        "        # obtain human bounding boxes using object detector\n",
        "        class_IDs, scores, bounding_boxs = detector(x)\n",
        "\n",
        "        # get pose estimations using AlphaPose\n",
        "        pose_input, upscale_bbox = detector_to_alpha_pose(frame, class_IDs, \n",
        "                                                          scores, bounding_boxs)\n",
        "\n",
        "        # add frame id, person count to frame-level results\n",
        "        image_id = f\"frame_{int(frame_count)}\"\n",
        "        n_people = upscale_bbox.shape[0]\n",
        "        frame_results['image_id'].append(image_id)\n",
        "        frame_results['person_count'].append(n_people)\n",
        "\n",
        "        # add frame_id, person bbox to person-level results\n",
        "        person_results['image_id'].append([image_id for x in range(n_people)])\n",
        "        person_results['bbox'].append(upscale_bbox)\n",
        "\n",
        "        # if we have predictions, obtain keypoint co-ords and confidences\n",
        "        if upscale_bbox is not None:\n",
        "\n",
        "            # obtain predicted heatmap\n",
        "            predicted_heatmap = estimator(pose_input.as_in_context(ctx))\n",
        "\n",
        "            # obtain keypoint co-ordinates from heatmap results\n",
        "            pred_coords, confidence = heatmap_to_coord(predicted_heatmap, \n",
        "                                                       upscale_bbox)\n",
        "            \n",
        "\n",
        "            # add person keypoints and confidences to person-level results\n",
        "            person_results['keypoints'].append(pred_coords.asnumpy())\n",
        "            person_results['confidences'].append(confidence.asnumpy())\n",
        "\n",
        "            ########################################################\n",
        "            ######### DOWNSTREAM MODELLING PROCESSING AREA #########\n",
        "            ########################################################\n",
        "            \n",
        "            ####### DISTANCE ESTIMATION / CLUSTERING (VALENTIN) #######\n",
        "            \n",
        "            # obtain x / y dims of frame\n",
        "            image_dim_y, image_dim_x = frame.shape[:2]\n",
        "            \n",
        "            # obtain estimation of parameters of the camera \n",
        "            _, _, theta, H, f = from_2D_to_3D(pred_coords, image_dim_x, \n",
        "                                              image_dim_y)\n",
        "            \n",
        "            # update parameters tracking lists\n",
        "            if len(theta_queue) > time_step_average:\n",
        "                theta_queue.popleft()\n",
        "                H_queue.popleft()\n",
        "                f_queue.popleft()\n",
        "            theta_queue.append(theta)\n",
        "            H_queue.append(H)\n",
        "            f_queue.append(f)\n",
        "            \n",
        "            # use z-scores to remove extreme values (95% confidence)\n",
        "            zscore_select_theta = np.where(\n",
        "                            np.abs((np.array(theta_queue) - np.mean(theta_queue)) \n",
        "                                   / np.std(theta_queue)) < 1.96)[0]\n",
        "            \n",
        "            zscore_select_H = np.where(\n",
        "                        np.abs((np.array(H_queue) - np.mean(H_queue)) \n",
        "                               / np.std(H_queue)) < 1.96)[0]\n",
        "            \n",
        "            zscore_select_f = np.where(\n",
        "                        np.abs((np.array(f_queue) - np.mean(f_queue)) \n",
        "                               / np.std(f_queue)) < 1.96)[0]\n",
        "            \n",
        "            zscore_select = np.intersect1d(zscore_select_theta, \n",
        "                                           np.intersect1d(zscore_select_H, \n",
        "                                                          zscore_select_f))\n",
        "            # remove extreme values\n",
        "            if len(zscore_select) > 10:\n",
        "                theta = np.mean(np.array(theta_queue)[zscore_select])\n",
        "                H = np.mean(np.array(H_queue)[zscore_select])\n",
        "                f = np.mean(np.array(f_queue)[zscore_select])\n",
        "            else:\n",
        "                theta, H, f = np.mean(theta_queue), np.mean(H_queue), np.mean(f_queue)\n",
        "            \n",
        "            # obtain estimation of persons' positions\n",
        "            X, Y, _, _, _ = from_2D_to_3D(pred_coords, image_dim_x, \n",
        "                                          image_dim_y, theta, H, f)\n",
        "            \n",
        "            # get positions into a single array\n",
        "            positions = np.column_stack([X, Y])\n",
        "            \n",
        "            # obtain social distancing compliance classification\n",
        "            respect_social_distancing = get_respect_social_distancing(positions, \n",
        "                                                                      social_distance=2)\n",
        "            \n",
        "            # get compliance proportion in scene\n",
        "            compliance_prop = np.array(np.bincount(respect_social_distancing, \n",
        "                                                   minlength=2)[1] \n",
        "                                       / respect_social_distancing.shape[0])\n",
        "            \n",
        "            # obtain social clusters\n",
        "            persons_clusters = get_clusters(positions, treshold=1)\n",
        "            \n",
        "            # get cluster classification (0 = not in a cluster, 1 = in a cluster)\n",
        "            in_cluster = (persons_clusters >= 0).astype(int)\n",
        "            \n",
        "            # plot top view of the scene\n",
        "            plot_top_view(positions, H, theta, f, image_dim_x, image_dim_y)\n",
        "            \n",
        "            # plot clusters with original image\n",
        "            plot_clusters(frame, persons_clusters, upscale_bbox)\n",
        "\n",
        "            # append positions, clusters and social distancing compliance results to per-person results\n",
        "            person_results['position'].append(positions)\n",
        "            person_results['in_cluster'].append(in_cluster)\n",
        "            person_results['respect_social_distancing'].append(respect_social_distancing)\n",
        "\n",
        "            # add number of clusters and compliance proportion to frame-results\n",
        "            frame_results['clusters_count'].append(np.max(persons_clusters)+1)\n",
        "            frame_results['social_distancing_compliance'].append(compliance_prop)\n",
        "            \n",
        "            \n",
        "            ####### POSE STATUS CLASSIFICATION (TONGFEI) #######\n",
        "            # insert code for distance estimation / clustering here #\n",
        "            label, score = behavior_analysis(pred_coords, upscale_bbox,behavior_analysis_model)\n",
        "            person_results['behavior'].append(label)\n",
        "            person_results['behavior_score'].append(score)\n",
        "\n",
        "            ####### MASK CLASSIFICATION CODE (BEN) #######\n",
        "\n",
        "            # obtain head regions boxes from our pose features\n",
        "            head_regions = compute_head_boxes(pred_coords)\n",
        "\n",
        "            # get extract tensor of head regions from original frame\n",
        "            region_tensor = get_image_region_array(frame, head_regions)\n",
        "            \n",
        "            # obtain probabilities (softmax normalised) from model\n",
        "            pred_probs = model_predict_probs(trained_module, region_tensor)\n",
        "\n",
        "            # obtain hard class labels from our probabilities\n",
        "            preds = get_prediction_labels(pred_probs).numpy()\n",
        "\n",
        "            # if desired, plot the mask classifier predictions\n",
        "            if SHOW_MASK_PREDS:\n",
        "                # plot our predicted mask results with original image\n",
        "                plot_mask_predictions(frame, preds, pred_probs, \n",
        "                                      head_regions)\n",
        "\n",
        "            # get mask proportion in scene, add to our total results\n",
        "            mask_prop = np.array(np.bincount(preds, minlength=1)[1] / preds.shape[0])\n",
        "\n",
        "            # append mask results to per-person results\n",
        "            person_results['mask_preds'].append(preds)\n",
        "            person_results['mask_pred_probs'].append(pred_probs)\n",
        "            person_results['mask_head_regions'].append(head_regions)\n",
        "\n",
        "            # add mask proportions to frame-results\n",
        "            frame_results['mask_proportions'].append(mask_prop)\n",
        "\n",
        "\n",
        "            ############################################\n",
        "            ######### DOWNSTREAM MODELLING END #########\n",
        "            ############################################\n",
        "            \n",
        "            # if selected, plot alphapose results\n",
        "            if SHOW_POSES:\n",
        "                # annotate our original frame with alphapose extracted keypoints\n",
        "                img = cv_plot_keypoints(frame, pred_coords, confidence, class_IDs, \n",
        "                                        bounding_boxs, scores,\n",
        "                                        box_thresh=0.5, keypoint_thresh=0.2)\n",
        "                \n",
        "                # plot alphapose results\n",
        "                plot_image(img)\n",
        "\n",
        "        # if no alphapose keypoints found, just plot the frame (image)\n",
        "        else:\n",
        "            plot_image(img)\n",
        "        \n",
        "        # increment current frame by amount selected by MODELLING_FPS\n",
        "        frame_count += fps / MODELLING_FPS\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_count))\n",
        "\n",
        "    # break loop if video is not available / ended\n",
        "    else:\n",
        "        break\n",
        "\n",
        "    if cv2.waitKey(1) == 27:\n",
        "        break\n",
        "\n",
        "# empty video capture cache\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLBUy0qT24pp"
      },
      "source": [
        "## 5. Conversion of final results into Pandas dataframes, and exporting to JSON objects:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SiIUJDg7--v"
      },
      "source": [
        "Lets convert the results obtained from this into a final form, suitable for further analysis / passing to the API & Dashboard:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BAEQzSy24pp",
        "outputId": "7e2bc668-ef84-4738-911c-f1c1eee8610c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Key image_id, length: 11\n",
            "Key person_count, length: 11\n",
            "Key clusters_count, length: 11\n",
            "Key social_distancing_compliance, length: 11\n",
            "Key mask_proportions, length: 11\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>person_count</th>\n",
              "      <th>clusters_count</th>\n",
              "      <th>social_distancing_compliance</th>\n",
              "      <th>mask_proportions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_25</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_37</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_50</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id  person_count  clusters_count  social_distancing_compliance  \\\n",
              "0   frame_0             8               2                      0.250000   \n",
              "1  frame_12             9               0                      0.111111   \n",
              "2  frame_25            10               1                      0.100000   \n",
              "3  frame_37            10               2                      0.000000   \n",
              "4  frame_50            10               2                      0.000000   \n",
              "\n",
              "   mask_proportions  \n",
              "0          0.250000  \n",
              "1          0.444444  \n",
              "2          0.500000  \n",
              "3          0.500000  \n",
              "4          0.700000  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_frame_results = {}\n",
        "\n",
        "# standardise frame-level results as np arrays for consistency\n",
        "for key in frame_results.keys():\n",
        "        print(f\"Key {key}, length: {len(frame_results[key])}\")\n",
        "        final_frame_results[key] = np.array(frame_results[key])\n",
        "\n",
        "# convert frame-level results to dataframe for ease of analysis\n",
        "final_frame_results = pd.DataFrame(final_frame_results)\n",
        "\n",
        "# preview results format\n",
        "final_frame_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1QUjpl124pp",
        "outputId": "c1fe9de1-52d9-4abc-d2ad-ac6a8b4a32cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>keypoints</th>\n",
              "      <th>confidences</th>\n",
              "      <th>position</th>\n",
              "      <th>in_cluster</th>\n",
              "      <th>respect_social_distancing</th>\n",
              "      <th>mask_preds</th>\n",
              "      <th>mask_pred_probs</th>\n",
              "      <th>mask_head_regions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[456.0, 143.0, 550.0, 385.0]</td>\n",
              "      <td>[[497.125, 192.15625], [497.125, 192.15625], [...</td>\n",
              "      <td>[[0.01501539722084999], [0.01663154922425747],...</td>\n",
              "      <td>[-0.07988895697910706, -1.3431437164557993]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.855712354183197, 0.14428766071796417]</td>\n",
              "      <td>[472, 162, 56, 56]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[340.0, 202.0, 438.0, 484.0]</td>\n",
              "      <td>[[386.9583435058594, 263.6875], [386.958343505...</td>\n",
              "      <td>[[0.5421698689460754], [0.49737271666526794], ...</td>\n",
              "      <td>[-0.8217262414533347, -1.9554725055927278]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.15879622101783752, 0.8412038087844849]</td>\n",
              "      <td>[350, 223, 69, 69]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[570.0, 40.0, 638.0, 203.0]</td>\n",
              "      <td>[[605.4166870117188, 75.65625], [606.833312988...</td>\n",
              "      <td>[[0.8332034945487976], [0.9014892578125], [0.8...</td>\n",
              "      <td>[1.2646109710061906, 1.8743114448602225]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8565556406974792, 0.14344438910484314]</td>\n",
              "      <td>[584, 52, 41, 41]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[469.0, 0.0, 514.0, 96.0]</td>\n",
              "      <td>[[496.1875, 1.5], [484.0, 34.5], [477.4375, 31...</td>\n",
              "      <td>[[0.0048622991889715195], [0.00185993721242994...</td>\n",
              "      <td>[-0.5381903208308965, 8.662718104336014]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8367882966995239, 0.1632116287946701]</td>\n",
              "      <td>[473, 24, 29, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[386.0, 0.0, 429.0, 86.0]</td>\n",
              "      <td>[[405.7083435058594, 73.90625], [420.041656494...</td>\n",
              "      <td>[[0.0012897616252303123], [0.00188375008292496...</td>\n",
              "      <td>[-2.656699920094782, 8.692234112604137]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8003365397453308, 0.199663445353508]</td>\n",
              "      <td>[399, 53, 29, 29]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id                          bbox  \\\n",
              "0  frame_0  [456.0, 143.0, 550.0, 385.0]   \n",
              "1  frame_0  [340.0, 202.0, 438.0, 484.0]   \n",
              "2  frame_0   [570.0, 40.0, 638.0, 203.0]   \n",
              "3  frame_0     [469.0, 0.0, 514.0, 96.0]   \n",
              "4  frame_0     [386.0, 0.0, 429.0, 86.0]   \n",
              "\n",
              "                                           keypoints  \\\n",
              "0  [[497.125, 192.15625], [497.125, 192.15625], [...   \n",
              "1  [[386.9583435058594, 263.6875], [386.958343505...   \n",
              "2  [[605.4166870117188, 75.65625], [606.833312988...   \n",
              "3  [[496.1875, 1.5], [484.0, 34.5], [477.4375, 31...   \n",
              "4  [[405.7083435058594, 73.90625], [420.041656494...   \n",
              "\n",
              "                                         confidences  \\\n",
              "0  [[0.01501539722084999], [0.01663154922425747],...   \n",
              "1  [[0.5421698689460754], [0.49737271666526794], ...   \n",
              "2  [[0.8332034945487976], [0.9014892578125], [0.8...   \n",
              "3  [[0.0048622991889715195], [0.00185993721242994...   \n",
              "4  [[0.0012897616252303123], [0.00188375008292496...   \n",
              "\n",
              "                                      position  in_cluster  \\\n",
              "0  [-0.07988895697910706, -1.3431437164557993]           1   \n",
              "1   [-0.8217262414533347, -1.9554725055927278]           1   \n",
              "2     [1.2646109710061906, 1.8743114448602225]           0   \n",
              "3     [-0.5381903208308965, 8.662718104336014]           0   \n",
              "4      [-2.656699920094782, 8.692234112604137]           1   \n",
              "\n",
              "   respect_social_distancing  mask_preds  \\\n",
              "0                          0           0   \n",
              "1                          0           1   \n",
              "2                          1           0   \n",
              "3                          0           0   \n",
              "4                          0           0   \n",
              "\n",
              "                             mask_pred_probs   mask_head_regions  \n",
              "0   [0.855712354183197, 0.14428766071796417]  [472, 162, 56, 56]  \n",
              "1  [0.15879622101783752, 0.8412038087844849]  [350, 223, 69, 69]  \n",
              "2  [0.8565556406974792, 0.14344438910484314]   [584, 52, 41, 41]  \n",
              "3   [0.8367882966995239, 0.1632116287946701]   [473, 24, 29, 29]  \n",
              "4    [0.8003365397453308, 0.199663445353508]   [399, 53, 29, 29]  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_person_results = {}\n",
        "\n",
        "# convert mask results into np array form and flatten\n",
        "for key in person_results.keys():\n",
        "        final_person_results[key] = np.concatenate(person_results[key], axis=0)\n",
        "        final_person_results[key] = final_person_results[key].tolist()\n",
        "\n",
        "# convert final person-level results to dataframe\n",
        "final_person_results = pd.DataFrame(final_person_results)\n",
        "\n",
        "# preview results\n",
        "final_person_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GapHltW624pq"
      },
      "source": [
        "Now that we have these as pandas dataframes, they can be exported easily into JSON objects, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQkaHbIc24pq"
      },
      "outputs": [],
      "source": [
        "frame_json_results = final_frame_results.to_json()\n",
        "person_json_results = final_person_results.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FinPvw9I24pq",
        "outputId": "2847ae8d-1735-45a0-a7fd-ae3406aa60cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"image_id\":{\"0\":\"frame_0\",\"1\":\"frame_12\",\"2\":\"frame_25\",\"3\":\"frame_37\",\"4\":\"frame_50\",\"5\":\"frame_62\",\"6\":\"frame_75\",\"7\":\"frame_87\",\"8\":\"frame_100\",\"9\":\"frame_112\",\"10\":\"frame_125\"},\"person_count\":{\"0\":8,\"1\":9,\"2\":10,\"3\":10,\"4\":10,\"5\":9,\"6\":9,\"7\":9,\"8\":9,\"9\":9,\"10\":8},\"clusters_count\":{\"0\":2,\"1\":0,\"2\":1,\"3\":2,\"4\":2,\"5\":2,\"6\":2,\"7\":2,\"8\":1,\"9\":3,\"10\":2},\"social_distancing_compliance\":{\"0\":0.25,\"1\":0.1111111111,\"2\":0.1,\"3\":0.0,\"4\":0.0,\"5\":0.2222222222,\"6\":0.0,\"7\":0.0,\"8\":0.0,\"9\":0.0,\"10\":0.125},\"mask_proportions\":{\"0\":0.25,\"1\":0.4444444444,\"2\":0.5,\"3\":0.5,\"4\":0.7,\"5\":0.6666666667,\"6\":0.6666666667,\"7\":0.6666666667,\"8\":0.3333333333,\"9\":0.4444444444,\"10\":0.625}}\n"
          ]
        }
      ],
      "source": [
        "print(frame_json_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6bJ9noH24pq",
        "outputId": "83826710-ea46-4e7d-98a4-c82e4018430d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"image_id\":{\"0\":\"frame_0\",\"1\":\"frame_0\",\"2\":\"frame_0\",\"3\":\"frame_0\",\"4\":\"frame_0\",\"5\":\"frame_0\",\"6\":\"frame_0\",\"7\":\"frame_0\",\"8\":\"frame_12\",\"9\":\"frame_12\",\"10\":\"frame_12\",\"11\":\"frame_12\",\"12\":\"frame_12\",\"13\":\"frame_12\",\"14\":\"frame_12\",\"15\":\"frame_12\",\"16\":\"frame_12\",\"17\":\"frame_25\",\"18\":\"frame_25\",\"19\":\"frame_25\",\"20\":\"frame_25\",\"21\":\"frame_25\",\"22\":\"frame_25\",\"23\":\"frame_25\",\"24\":\"frame_25\",\"25\":\"frame_25\",\"26\":\"frame_25\",\"27\":\"frame_37\",\"28\":\"frame_37\",\"29\":\"frame_37\",\"30\":\"frame_37\",\"31\":\"frame_37\",\"32\":\"frame_37\",\"33\":\"frame_37\",\"34\":\"frame_37\",\"35\":\"frame_37\",\"36\":\"frame_37\",\"37\":\"frame_50\",\"38\":\"frame_50\",\"39\":\"frame_50\",\"40\":\"frame_50\",\"41\":\"frame_50\",\"42\":\"frame_50\",\"43\":\"frame_50\",\"44\":\"frame_50\",\"45\":\"frame_50\",\"46\":\"frame_50\",\"47\":\"frame_62\",\"48\":\"frame_62\",\"49\":\"frame_62\",\"50\":\"frame_62\",\"51\":\"frame_62\",\"52\":\"frame_62\",\"53\":\"frame_62\",\"54\":\"frame_62\",\"55\":\"frame_62\",\"56\":\"frame_75\",\"57\":\"frame_75\",\"58\":\"frame_75\",\"59\":\"frame_75\",\"60\":\"frame_75\",\"61\":\"frame_75\",\"62\":\"frame_75\",\"63\":\"frame_75\",\"64\":\"frame_75\",\"65\":\"frame_87\",\"66\":\"frame_87\",\"67\":\"frame_87\",\"68\":\"frame_87\",\"69\":\"frame_87\",\"70\":\"frame_87\",\"71\":\"frame_87\",\"72\":\"frame_87\",\"73\":\"frame_87\",\"74\":\"frame_100\",\"75\":\"frame_100\",\"76\":\"frame_100\",\"77\":\"frame_100\",\"78\":\"frame_100\",\"79\":\"frame_100\",\"80\":\"frame_100\",\"81\":\"frame_100\",\"82\":\"frame_100\",\"83\":\"frame_112\",\"84\":\"frame_112\",\"85\":\"frame_112\",\"86\":\"frame_112\",\"87\":\"frame_112\",\"88\":\"frame_112\",\"89\":\"frame_112\",\"90\":\"frame_112\",\"91\":\"frame_112\",\"92\":\"frame_125\",\"93\":\"frame_125\",\"94\":\"frame_125\",\"95\":\"frame_125\",\"96\":\"frame_125\",\"97\":\"frame_125\",\"98\":\"frame_125\",\"99\":\"frame_125\"},\"bbox\":{\"0\":[456.0,143.0,550.0,385.0],\"1\":[340.0,202.0,438.0,484.0],\"2\":[570.0,40.0,638.0,203.0],\"3\":[469.0,0.0,514.0,96.0],\"4\":[386.0,0.0,429.0,86.0],\"5\":[424.0,0.0,466.0,97.0],\"6\":[605.0,225.0,702.0,472.0],\"7\":[532.0,0.0,566.0,59.0],\"8\":[330.0,234.0,440.0,484.0],\"9\":[452.0,123.0,536.0,336.0],\"10\":[595.0,268.0,708.0,484.0],\"11\":[459.0,0.0,506.0,119.0],\"12\":[568.0,53.0,644.0,237.0],\"13\":[414.0,0.0,464.0,117.0],\"14\":[537.0,0.0,576.0,77.0],\"15\":[385.0,0.0,426.0,101.0],\"16\":[510.0,0.0,548.0,68.0],\"17\":[332.0,267.0,450.0,484.0],\"18\":[445.0,0.0,504.0,130.0],\"19\":[440.0,102.0,522.0,317.0],\"20\":[403.0,0.0,454.0,136.0],\"21\":[589.0,311.0,694.0,484.0],\"22\":[543.0,0.0,585.0,89.0],\"23\":[507.0,0.0,551.0,81.0],\"24\":[570.0,65.0,642.0,246.0],\"25\":[374.0,0.0,422.0,128.0],\"26\":[474.0,0.0,508.0,80.0],\"27\":[438.0,85.0,516.0,292.0],\"28\":[563.0,82.0,639.0,274.0],\"29\":[324.0,295.0,449.0,484.0],\"30\":[581.0,374.0,694.0,484.0],\"31\":[362.0,0.0,418.0,150.0],\"32\":[425.0,0.0,492.0,138.0],\"33\":[396.0,0.0,445.0,147.0],\"34\":[546.0,0.0,593.0,98.0],\"35\":[466.0,0.0,511.0,92.0],\"36\":[505.0,0.0,546.0,95.0],\"37\":[436.0,61.0,513.0,265.0],\"38\":[336.0,310.0,442.0,484.0],\"39\":[412.0,0.0,477.0,153.0],\"40\":[562.0,96.0,643.0,290.0],\"41\":[544.0,0.0,596.0,113.0],\"42\":[378.0,0.0,429.0,160.0],\"43\":[357.0,0.0,399.0,152.0],\"44\":[461.0,0.0,509.0,101.0],\"45\":[585.0,426.0,685.0,484.0],\"46\":[497.0,0.0,551.0,108.0],\"47\":[559.0,109.0,643.0,324.0],\"48\":[366.0,313.0,470.0,484.0],\"49\":[434.0,50.0,503.0,231.0],\"50\":[344.0,0.0,385.0,173.0],\"51\":[537.0,0.0,594.0,127.0],\"52\":[503.0,0.0,547.0,114.0],\"53\":[461.0,0.0,509.0,118.0],\"54\":[367.0,11.0,418.0,183.0],\"55\":[406.0,15.0,467.0,168.0],\"56\":[400.0,20.0,452.0,184.0],\"57\":[552.0,129.0,644.0,355.0],\"58\":[354.0,20.0,408.0,194.0],\"59\":[536.0,0.0,597.0,145.0],\"60\":[501.0,0.0,550.0,132.0],\"61\":[433.0,30.0,503.0,221.0],\"62\":[394.0,330.0,504.0,484.0],\"63\":[330.0,3.0,376.0,195.0],\"64\":[464.0,0.0,515.0,130.0],\"65\":[505.0,0.0,556.0,151.0],\"66\":[468.0,0.0,518.0,151.0],\"67\":[389.0,29.0,444.0,201.0],\"68\":[438.0,26.0,498.0,210.0],\"69\":[541.0,0.0,592.0,153.0],\"70\":[539.0,152.0,631.0,364.0],\"71\":[319.0,19.0,366.0,198.0],\"72\":[342.0,36.0,398.0,223.0],\"73\":[424.0,359.0,531.0,484.0],\"74\":[534.0,14.0,589.0,183.0],\"75\":[423.0,21.0,488.0,188.0],\"76\":[382.0,46.0,435.0,215.0],\"77\":[474.0,9.0,524.0,173.0],\"78\":[507.0,174.0,606.0,395.0],\"79\":[332.0,51.0,387.0,232.0],\"80\":[506.0,10.0,554.0,175.0],\"81\":[304.0,37.0,355.0,232.0],\"82\":[465.0,396.0,566.0,484.0],\"83\":[427.0,7.0,480.0,166.0],\"84\":[505.0,19.0,558.0,187.0],\"85\":[465.0,15.0,520.0,193.0],\"86\":[484.0,196.0,595.0,446.0],\"87\":[370.0,47.0,427.0,221.0],\"88\":[534.0,25.0,593.0,206.0],\"89\":[321.0,56.0,385.0,247.0],\"90\":[292.0,54.0,353.0,248.0],\"91\":[500.0,427.0,611.0,484.0],\"92\":[423.0,0.0,479.0,149.0],\"93\":[357.0,45.0,416.0,216.0],\"94\":[453.0,19.0,513.0,209.0],\"95\":[279.0,49.0,347.0,265.0],\"96\":[536.0,33.0,590.0,216.0],\"97\":[461.0,214.0,566.0,467.0],\"98\":[329.0,61.0,388.0,250.0],\"99\":[505.0,19.0,569.0,211.0]},\"keypoints\":{\"0\":[[497.125,192.15625],[497.125,192.15625],[504.9583129883,188.375],[497.125,192.15625],[504.9583129883,188.375],[493.2083129883,214.84375],[512.7916870117,211.0625],[485.375,237.53125],[516.7083129883,241.3125],[489.2916870117,218.625],[516.7083129883,264.0],[497.125,264.0],[508.875,264.0],[499.0833129883,301.8125],[504.9583129883,294.25],[501.0416870117,335.84375],[503.0,332.0625]],\"1\":[[386.9583435059,263.6875],[386.9583435059,259.28125],[382.875,259.28125],[389.0,254.875],[380.8333435059,254.875],[397.1666564941,268.09375],[376.75,272.5],[401.25,298.9375],[372.6666564941,303.34375],[403.2916564941,329.78125],[374.7083435059,329.78125],[395.125,334.1875],[382.875,334.1875],[397.1666564941,360.625],[382.875,378.25],[397.1666564941,373.84375],[386.9583435059,422.3125]],\"2\":[[605.4166870117,75.65625],[606.8333129883,70.5625],[604.0,73.109375],[609.6666870117,73.109375],[601.1666870117,73.109375],[612.5,83.296875],[598.3333129883,83.296875],[615.3333129883,103.671875],[592.6666870117,103.671875],[615.3333129883,121.5],[591.25,121.5],[609.6666870117,121.5],[599.75,121.5],[611.0833129883,146.96875],[599.75,152.0625],[604.0,162.25],[599.75,177.53125]],\"3\":[[496.1875,1.5],[484.0,34.5],[477.4375,31.5],[491.5,75.0],[489.625,52.5],[497.125,1.5],[485.875,1.5],[499.0,16.5],[483.0625,13.5],[500.875,33.0],[482.125,31.5],[494.3125,30.0],[487.75,28.5],[493.375,54.0],[486.8125,51.0],[492.4375,75.0],[491.5,58.5]],\"4\":[[405.7083435059,73.90625],[420.0416564941,65.84375],[411.0833435059,65.84375],[415.5625,68.53125],[416.4583435059,67.1875],[386.8958435059,21.5],[412.875,63.15625],[420.0416564941,1.34375],[398.5416564941,4.03125],[417.3541564941,17.46875],[397.6458435059,22.84375],[413.7708435059,16.125],[404.8125,16.125],[413.7708435059,44.34375],[407.5,43.0],[415.5625,67.1875],[411.0833435059,65.84375]],\"5\":[[444.125,28.796875],[446.75,65.171875],[446.75,66.6875],[454.625,25.765625],[446.75,50.015625],[452.0,1.515625],[438.875,1.515625],[452.875,9.09375],[438.0,4.546875],[453.75,25.765625],[436.25,24.25],[447.625,27.28125],[441.5,27.28125],[446.75,51.53125],[444.125,48.5],[446.75,74.265625],[446.75,63.65625]],\"6\":[[657.5416870117,282.890625],[659.5625,279.03125],[655.5208129883,275.171875],[661.5833129883,279.03125],[651.4791870117,275.171875],[665.625,294.46875],[643.3958129883,294.46875],[667.6458129883,321.484375],[637.3333129883,325.34375],[667.6458129883,348.5],[635.3125,344.640625],[657.5416870117,344.640625],[645.4166870117,340.78125],[653.5,383.234375],[647.4375,375.515625],[647.4375,421.828125],[647.4375,375.515625]],\"7\":[[554.6666870117,1.84375],[551.125,32.265625],[546.875,43.328125],[551.125,33.1875],[549.7083129883,35.953125],[545.4583129883,24.890625],[548.2916870117,42.40625],[548.2916870117,38.71875],[548.2916870117,16.59375],[551.8333129883,16.59375],[546.875,45.171875],[554.6666870117,0.921875],[544.75,0.921875],[553.25,21.203125],[546.875,23.046875],[551.125,31.34375],[546.875,43.328125]],\"8\":[[382.7083435059,296.5],[385.0,292.59375],[380.4166564941,292.59375],[389.5833435059,288.6875],[375.8333435059,288.6875],[396.4583435059,300.40625],[368.9583435059,304.3125],[403.3333435059,327.75],[364.375,339.46875],[405.625,355.09375],[366.6666564941,374.625],[394.1666564941,370.71875],[378.125,370.71875],[396.4583435059,413.6875],[380.4166564941,405.875],[396.4583435059,464.46875],[385.0,429.3125]],\"9\":[[488.75,162.9375],[488.75,159.609375],[497.5,162.9375],[488.75,162.9375],[497.5,162.9375],[485.25,186.234375],[504.5,182.90625],[480.0,206.203125],[508.0,212.859375],[483.5,186.234375],[504.5,226.171875],[488.75,232.828125],[501.0,232.828125],[485.25,256.125],[499.25,259.453125],[488.75,292.734375],[495.75,296.0625]],\"10\":[[656.2083129883,322.0],[658.5625,318.625],[653.8541870117,315.25],[665.625,318.625],[649.1458129883,315.25],[670.3333129883,338.875],[639.7291870117,332.125],[672.6875,369.25],[627.9583129883,359.125],[667.9791870117,399.625],[625.6041870117,379.375],[656.2083129883,382.75],[639.7291870117,382.75],[651.5,416.5],[637.375,426.625],[646.7916870117,430.0],[635.0208129883,470.5]],\"11\":[[480.5416564941,1.859375],[481.5208435059,1.859375],[479.5625,1.859375],[484.4583435059,1.859375],[478.5833435059,1.859375],[487.3958435059,14.875],[477.6041564941,13.015625],[489.3541870117,31.609375],[476.625,29.75],[488.375,48.34375],[475.6458435059,44.625],[486.4166564941,44.625],[479.5625,44.625],[487.3958435059,65.078125],[479.5625,66.9375],[488.375,79.953125],[479.5625,91.109375]],\"12\":[[609.1666870117,90.375],[610.75,87.5],[607.5833129883,87.5],[612.3333129883,90.375],[604.4166870117,87.5],[615.5,101.875],[601.25,101.875],[618.6666870117,124.875],[596.5,122.0],[618.6666870117,139.25],[594.9166870117,142.125],[612.3333129883,142.125],[601.25,139.25],[609.1666870117,173.75],[601.25,162.25],[606.0,196.75],[601.25,176.625]],\"13\":[[436.9166564941,0.0],[427.5416564941,32.90625],[435.875,89.578125],[443.1666564941,0.0],[436.9166564941,1.828125],[444.2083435059,9.140625],[432.75,7.3125],[446.2916564941,27.421875],[431.7083435059,20.109375],[443.1666564941,42.046875],[427.5416564941,31.078125],[442.125,40.21875],[435.875,40.21875],[444.2083435059,63.984375],[435.875,65.8125],[444.2083435059,80.4375],[435.875,91.40625]],\"14\":[[557.3125,9.625],[552.4375,2.40625],[552.4375,6.015625],[546.75,1.203125],[558.125,58.953125],[537.8125,9.625],[552.4375,6.015625],[565.4375,1.203125],[548.375,50.53125],[562.1875,10.828125],[553.25,3.609375],[561.375,10.828125],[553.25,10.828125],[559.75,36.09375],[551.625,32.484375],[558.9375,58.953125],[550.0,49.328125]],\"15\":[[425.1458435059,0.0],[406.3541564941,69.4375],[408.9166564941,80.484375],[409.7708435059,83.640625],[409.7708435059,61.546875],[412.3333435059,1.578125],[401.2291564941,0.0],[414.0416564941,12.625],[396.9583435059,11.046875],[413.1875,29.984375],[397.8125,29.984375],[410.625,31.5625],[402.9375,29.984375],[409.7708435059,59.96875],[402.0833435059,59.96875],[409.7708435059,83.640625],[407.2083435059,67.859375]],\"16\":[[537.7083129883,1.0625],[529.7916870117,36.125],[529.0,42.5],[537.7083129883,1.0625],[529.0,43.5625],[530.5833129883,1.0625],[528.2083129883,46.75],[528.2083129883,52.0625],[528.2083129883,53.125],[538.5,6.375],[528.2083129883,52.0625],[531.375,4.25],[523.4583129883,5.3125],[532.9583129883,27.625],[525.8333129883,28.6875],[529.0,38.25],[527.4166870117,51.0]],\"17\":[[395.9166564941,324.640625],[398.375,321.25],[391.0,321.25],[398.375,317.859375],[383.625,321.25],[408.2083129883,331.421875],[371.3333435059,334.8125],[418.0416870117,361.9375],[363.9583435059,365.328125],[418.0416870117,399.234375],[363.9583435059,395.84375],[403.2916870117,406.015625],[381.1666564941,406.015625],[403.2916870117,450.09375],[378.7083435059,446.703125],[400.8333129883,480.609375],[383.625,477.21875]],\"18\":[[470.8125,14.21875],[473.2708435059,12.1875],[470.8125,12.1875],[475.7291564941,12.1875],[469.5833435059,12.1875],[480.6458435059,24.375],[467.125,22.34375],[484.3333129883,40.625],[463.4375,38.59375],[485.5625,58.90625],[463.4375,48.75],[476.9583435059,56.875],[470.8125,56.875],[475.7291564941,81.25],[473.2708435059,79.21875],[475.7291564941,103.59375],[474.5,97.5]],\"19\":[[474.1666870117,142.3125],[489.5416870117,206.140625],[481.0,142.3125],[474.1666870117,142.3125],[482.7083129883,142.3125],[470.75,162.46875],[487.8333129883,159.109375],[465.625,182.625],[492.9583129883,189.34375],[472.4583129883,165.828125],[491.25,209.5],[474.1666870117,202.78125],[486.125,202.78125],[474.1666870117,226.296875],[484.4166870117,233.015625],[475.875,259.890625],[487.8333129883,266.609375]],\"20\":[[423.1875,10.625],[424.25,6.375],[423.1875,6.375],[428.5,8.5],[423.1875,6.375],[432.75,21.25],[422.125,19.125],[435.9375,38.25],[422.125,36.125],[437.0,53.125],[420.0,51.0],[430.625,53.125],[424.25,53.125],[429.5625,80.75],[427.4375,78.625],[430.625,108.375],[429.5625,106.25]],\"21\":[[645.875,365.0625],[650.25,359.65625],[641.5,359.65625],[656.8125,359.65625],[637.125,356.953125],[663.375,378.578125],[624.0,375.875],[667.75,408.3125],[615.25,405.609375],[665.5625,438.046875],[613.0625,432.640625],[652.4375,440.75],[628.375,438.046875],[648.0625,478.59375],[628.375,478.59375],[639.3125,356.953125],[650.25,362.359375]],\"22\":[[555.25,1.390625],[560.5,61.1875],[561.375,65.359375],[561.375,62.578125],[559.625,69.53125],[571.0,1.390625],[562.25,65.359375],[571.0,9.734375],[556.125,1.390625],[565.75,19.46875],[551.75,1.390625],[567.5,18.078125],[560.5,15.296875],[564.0,43.109375],[560.5,44.5],[562.25,63.96875],[560.5,65.359375]],\"23\":[[525.3333129883,16.453125],[529.9166870117,62.015625],[526.25,54.421875],[529.0,62.015625],[530.8333129883,39.234375],[529.9166870117,10.125],[525.3333129883,1.265625],[537.25,1.265625],[522.5833129883,1.265625],[539.0833129883,12.65625],[539.0833129883,13.921875],[532.6666870117,11.390625],[524.4166870117,12.65625],[530.8333129883,39.234375],[525.3333129883,36.703125],[529.9166870117,62.015625],[527.1666870117,53.15625]],\"24\":[[607.5,104.59375],[610.5,101.765625],[606.0,101.765625],[612.0,104.59375],[604.5,104.59375],[615.0,118.734375],[600.0,115.90625],[618.0,141.359375],[595.5,138.53125],[616.5,161.15625],[594.0,158.328125],[610.5,161.15625],[601.5,158.328125],[609.0,183.78125],[600.0,189.4375],[606.0,197.921875],[600.0,220.546875]],\"25\":[[398.0,6.0],[399.0,4.0],[397.0,4.0],[401.0,2.0],[395.0,2.0],[404.0,10.0],[393.0,12.0],[407.0,28.0],[391.0,26.0],[407.0,42.0],[392.0,42.0],[403.0,44.0],[396.0,44.0],[404.0,68.0],[397.0,74.0],[405.0,86.0],[398.0,104.0]],\"26\":[[482.5,11.25],[493.125,62.5],[492.4166564941,62.5],[478.25,8.75],[483.2083435059,10.0],[486.75,23.75],[486.75,23.75],[490.2916564941,41.25],[490.2916564941,41.25],[491.7083435059,57.5],[491.7083435059,58.75],[474.7083435059,55.0],[483.2083435059,57.5],[490.2916564941,40.0],[482.5,75.0],[492.4166564941,62.5],[492.4166564941,62.5]],\"27\":[[472.125,123.8125],[472.125,120.578125],[480.25,123.8125],[470.5,123.8125],[478.625,123.8125],[467.25,143.21875],[485.125,143.21875],[464.0,165.859375],[488.375,172.328125],[465.625,152.921875],[488.375,191.734375],[470.5,194.96875],[480.25,194.96875],[472.125,220.84375],[480.25,217.609375],[473.75,256.421875],[477.0,230.546875]],\"28\":[[602.5833129883,118.0],[604.1666870117,115.0],[601.0,115.0],[607.3333129883,118.0],[599.4166870117,118.0],[610.5,133.0],[594.6666870117,133.0],[612.0833129883,157.0],[589.9166870117,157.0],[612.0833129883,175.0],[588.3333129883,178.0],[605.75,181.0],[596.25,178.0],[604.1666870117,211.0],[596.25,208.0],[602.5833129883,235.0],[597.8333129883,229.0]],\"29\":[[391.7083435059,357.015625],[394.3125,348.15625],[386.5,354.0625],[394.3125,348.15625],[373.4791564941,354.0625],[399.5208435059,354.0625],[357.8541564941,371.78125],[412.5416564941,383.59375],[350.0416564941,410.171875],[420.3541564941,410.171875],[355.25,445.609375],[402.125,427.890625],[373.4791564941,433.796875],[404.7291564941,478.09375],[373.4791564941,478.09375],[383.8958435059,357.015625],[386.5,351.109375]],\"30\":[[644.5625,420.40625],[651.625,418.6875],[642.2083129883,415.25],[663.3958129883,418.6875],[637.5,411.8125],[672.8125,434.15625],[618.6666870117,427.28125],[677.5208129883,465.09375],[602.1875,456.5],[670.4583129883,477.125],[613.9583129883,471.96875],[653.9791870117,475.40625],[621.0208129883,475.40625],[656.3333129883,416.96875],[581.0,480.5625],[644.5625,416.96875],[639.8541870117,418.6875]],\"31\":[[391.1666564941,14.0625],[390.0,9.375],[388.8333435059,11.71875],[392.3333435059,9.375],[387.6666564941,11.71875],[395.8333435059,25.78125],[384.1666564941,23.4375],[398.1666564941,65.625],[383.0,39.84375],[398.1666564941,60.9375],[398.1666564941,58.59375],[392.3333435059,63.28125],[387.6666564941,67.96875],[392.3333435059,89.0625],[393.5,91.40625],[402.8333435059,112.5],[402.8333435059,112.5]],\"32\":[[457.1041564941,23.71875],[459.8958435059,21.5625],[457.1041564941,21.5625],[464.0833435059,21.5625],[458.5,23.71875],[469.6666564941,36.65625],[457.1041564941,32.34375],[472.4583435059,53.90625],[451.5208435059,47.4375],[472.4583435059,71.15625],[445.9375,51.75],[466.875,69.0],[458.5,66.84375],[468.2708435059,92.71875],[457.1041564941,90.5625],[468.2708435059,118.59375],[459.8958435059,109.96875]],\"33\":[[415.3958435059,22.96875],[416.4166564941,20.671875],[415.3958435059,20.671875],[419.4791564941,20.671875],[418.4583435059,25.265625],[423.5625,32.15625],[414.375,32.15625],[425.6041564941,52.828125],[414.375,50.53125],[423.5625,71.203125],[413.3541564941,64.3125],[422.5416564941,68.90625],[416.4166564941,68.90625],[423.5625,94.171875],[416.4166564941,94.171875],[423.5625,117.140625],[419.4791564941,114.84375]],\"34\":[[576.3541870117,0.0],[556.7708129883,16.84375],[563.625,73.5],[567.5416870117,73.5],[568.5208129883,71.96875],[574.3958129883,1.53125],[562.6458129883,1.53125],[577.3333129883,16.84375],[560.6875,13.78125],[578.3125,33.6875],[555.7916870117,16.84375],[571.4583129883,32.15625],[563.625,30.625],[570.4791870117,53.59375],[564.6041870117,52.0625],[571.4583129883,73.5],[565.5833129883,73.5]],\"35\":[[473.5,24.4375],[474.4375,21.5625],[471.625,21.5625],[475.375,23.0],[469.75,23.0],[480.0625,35.9375],[466.9375,35.9375],[483.8125,54.625],[483.8125,51.75],[482.875,71.875],[497.875,27.3125],[477.25,69.0],[466.9375,69.0],[478.1875,89.125],[466.0,89.125],[488.5,73.3125],[488.5,73.3125]],\"36\":[[525.5,28.203125],[528.0625,63.828125],[522.0833129883,74.21875],[528.0625,65.3125],[527.2083129883,63.828125],[533.1875,0.0],[518.6666870117,0.0],[533.1875,10.390625],[517.8125,10.390625],[531.4791870117,20.78125],[521.2291870117,13.359375],[529.7708129883,26.71875],[522.9375,28.203125],[528.9166870117,48.984375],[522.0833129883,51.953125],[528.0625,63.828125],[522.0833129883,75.703125]],\"37\":[[469.6875,99.25],[469.6875,182.125],[476.1041870117,223.5625],[469.6875,99.25],[477.7083129883,99.25],[466.4791564941,121.5625],[482.5208129883,118.375],[463.2708435059,150.25],[487.3333129883,143.875],[460.0625,163.0],[484.125,147.0625],[469.6875,169.375],[479.3125,169.375],[469.6875,182.125],[477.7083129883,191.6875],[468.0833435059,194.875],[476.1041870117,223.5625]],\"38\":[[400.0416870117,367.09375],[402.25,361.65625],[395.625,364.375],[402.25,358.9375],[382.375,364.375],[400.0416870117,367.09375],[366.9166564941,391.5625],[408.875,388.84375],[362.5,435.0625],[415.5,416.03125],[373.5416564941,467.6875],[406.6666870117,451.375],[386.7916564941,462.25],[413.2916870117,478.5625],[389.0,481.28125],[400.0416870117,372.53125],[386.7916564941,481.28125]],\"39\":[[440.4375,31.078125],[441.7916564941,28.6875],[440.4375,28.6875],[445.8541564941,31.078125],[441.7916564941,31.078125],[451.2708435059,43.03125],[440.4375,40.640625],[455.3333435059,62.15625],[437.7291564941,54.984375],[455.3333435059,78.890625],[435.0208435059,59.765625],[449.9166564941,76.5],[443.1458435059,76.5],[451.2708435059,100.40625],[443.1458435059,102.796875],[456.6875,121.921875],[445.8541564941,126.703125]],\"40\":[[605.875,135.40625],[607.5625,132.375],[602.5,132.375],[609.25,135.40625],[599.125,132.375],[610.9375,147.53125],[595.75,144.5],[616.0,171.78125],[590.6875,168.75],[616.0,196.03125],[587.3125,193.0],[607.5625,196.03125],[597.4375,193.0],[604.1875,229.375],[595.75,229.375],[599.125,250.59375],[595.75,241.5]],\"41\":[[572.1666870117,1.765625],[573.25,1.765625],[570.0,0.0],[574.3333129883,1.765625],[567.8333129883,1.765625],[576.5,7.0625],[564.5833129883,7.0625],[578.6666870117,24.71875],[562.4166870117,22.953125],[579.75,42.375],[560.25,38.84375],[574.3333129883,42.375],[566.75,40.609375],[572.1666870117,63.5625],[565.6666870117,61.796875],[571.0833129883,86.515625],[565.6666870117,74.15625]],\"42\":[[398.1875,32.5],[399.25,30.0],[398.1875,30.0],[402.4375,30.0],[399.25,27.5],[406.6875,42.5],[398.1875,40.0],[409.875,62.5],[397.125,57.5],[410.9375,80.0],[396.0625,72.5],[405.625,77.5],[400.3125,75.0],[404.5625,105.0],[400.3125,102.5],[407.75,122.5],[403.5,127.5]],\"43\":[[378.0,19.0],[378.875,16.625],[377.125,16.625],[380.625,16.625],[376.25,19.0],[382.375,30.875],[374.5,30.875],[382.375,52.25],[372.75,47.5],[382.375,68.875],[373.625,64.125],[381.5,66.5],[377.125,68.875],[382.375,92.625],[376.25,97.375],[382.375,118.75],[379.75,114.0]],\"44\":[[480.0,0.0],[483.0,77.328125],[483.0,80.484375],[488.0,66.28125],[487.0,69.4375],[491.0,1.578125],[479.0,1.578125],[493.0,20.515625],[476.0,17.359375],[493.0,36.296875],[475.0,34.71875],[489.0,34.71875],[481.0,34.71875],[489.0,59.96875],[482.0,59.96875],[488.0,69.4375],[483.0,80.484375]],\"45\":[[628.75,459.53125],[635.0,458.625],[626.6666870117,456.8125],[649.5833129883,457.71875],[622.5,455.0],[664.1666870117,466.78125],[607.9166870117,463.15625],[676.6666870117,482.1875],[595.4166870117,482.1875],[682.9166870117,483.09375],[607.9166870117,482.1875],[653.75,482.1875],[620.4166870117,482.1875],[624.5833129883,454.09375],[597.5,465.875],[624.5833129883,457.71875],[601.6666870117,464.96875]],\"46\":[[529.625,1.6875],[530.75,1.6875],[530.75,3.375],[517.25,18.5625],[531.875,1.6875],[530.75,3.375],[516.125,3.375],[533.0,18.5625],[512.75,20.25],[536.375,32.0625],[517.25,20.25],[527.375,37.125],[519.5,35.4375],[526.25,59.0625],[519.5,57.375],[526.25,82.6875],[520.625,77.625]],\"47\":[[602.75,152.671875],[604.5,149.3125],[601.0,149.3125],[608.0,152.671875],[597.5,152.671875],[609.75,166.109375],[594.0,162.75],[613.25,189.625],[588.75,186.265625],[613.25,216.5],[585.25,209.78125],[604.5,209.78125],[594.0,209.78125],[597.5,246.734375],[594.0,243.375],[597.5,280.328125],[597.5,273.609375]],\"48\":[[437.5,369.109375],[437.5,363.765625],[433.1666564941,366.4375],[405.0,481.328125],[418.0,366.4375],[435.3333435059,377.125],[402.8333435059,390.484375],[439.6666564941,401.171875],[392.0,433.234375],[446.1666564941,425.21875],[400.6666564941,467.96875],[431.0,446.59375],[411.5,454.609375],[428.8333435059,475.984375],[405.0,481.328125],[433.1666564941,369.109375],[392.0,433.234375]],\"49\":[[464.1875,81.109375],[464.1875,75.453125],[469.9375,78.28125],[462.75,83.9375],[471.375,83.9375],[459.875,100.90625],[475.6875,100.90625],[457.0,126.359375],[478.5625,123.53125],[455.5625,140.5],[480.0,140.5],[462.75,140.5],[472.8125,140.5],[464.1875,168.78125],[474.25,168.78125],[465.625,197.0625],[474.25,197.0625]],\"50\":[[364.5,27.03125],[365.3541564941,21.625],[362.7916564941,24.328125],[366.2083435059,27.03125],[362.7916564941,27.03125],[369.625,37.84375],[361.0833435059,43.25],[369.625,64.875],[359.375,64.875],[370.4791564941,45.953125],[361.0833435059,78.390625],[367.0625,70.28125],[364.5,83.796875],[373.0416564941,110.828125],[363.6458435059,108.125],[366.2083435059,137.859375],[366.2083435059,137.859375]],\"51\":[[565.5,7.9375],[566.6875,5.953125],[564.3125,5.953125],[569.0625,5.953125],[563.125,5.953125],[572.625,17.859375],[563.125,17.859375],[575.0,37.703125],[560.75,33.734375],[572.625,53.578125],[553.625,35.71875],[570.25,53.578125],[564.3125,53.578125],[570.25,75.40625],[564.3125,77.390625],[569.0625,87.3125],[564.3125,99.21875]],\"52\":[[527.75,1.78125],[520.4166870117,28.5],[522.25,87.28125],[528.6666870117,1.78125],[526.8333129883,62.34375],[532.3333129883,10.6875],[519.5,10.6875],[532.3333129883,28.5],[517.6666870117,24.9375],[531.4166870117,44.53125],[523.1666870117,28.5],[528.6666870117,46.3125],[522.25,44.53125],[526.8333129883,67.6875],[522.25,67.6875],[525.9166870117,87.28125],[522.25,89.0625]],\"53\":[[490.0,1.84375],[480.0,44.25],[484.0,90.34375],[483.0,88.5],[481.0,1.84375],[491.0,7.375],[479.0,9.21875],[493.0,25.8125],[477.0,29.5],[494.0,38.71875],[478.0,46.09375],[489.0,42.40625],[482.0,42.40625],[488.0,70.0625],[482.0,68.21875],[488.0,97.71875],[483.0,90.34375]],\"54\":[[388.25,45.9375],[389.3125,43.25],[388.25,43.25],[392.5,43.25],[389.3125,43.25],[395.6875,54.0],[388.25,54.0],[398.875,75.5],[387.1875,70.125],[397.8125,97.0],[386.125,86.25],[394.625,91.625],[388.25,88.9375],[393.5625,118.5],[389.3125,113.125],[393.5625,145.375],[390.375,121.1875]],\"55\":[[431.4166564941,43.6875],[432.6875,41.296875],[432.6875,41.296875],[436.5,41.296875],[432.6875,41.296875],[441.5833435059,55.640625],[431.4166564941,53.25],[445.3958435059,77.15625],[430.1458435059,67.59375],[447.9375,91.5],[426.3333435059,74.765625],[440.3125,91.5],[435.2291564941,91.5],[439.0416564941,115.40625],[436.5,113.015625],[437.7708435059,141.703125],[441.5833435059,132.140625]],\"56\":[[421.6666564941,55.875],[422.75,53.3125],[421.6666564941,53.3125],[423.8333435059,50.75],[423.8333435059,48.1875],[429.25,66.125],[421.6666564941,61.0],[432.5,84.0625],[420.5833435059,76.375],[429.25,107.125],[418.4166564941,91.75],[429.25,96.875],[423.8333435059,96.875],[429.25,117.375],[422.75,125.0625],[431.4166564941,143.0],[423.8333435059,153.25]],\"57\":[[598.0,174.90625],[599.9166870117,171.375],[596.0833129883,171.375],[601.8333129883,174.90625],[592.25,171.375],[605.6666870117,189.03125],[588.4166870117,185.5],[611.4166870117,213.75],[584.5833129883,210.21875],[613.3333129883,234.9375],[582.6666870117,234.9375],[601.8333129883,234.9375],[590.3333129883,231.40625],[598.0,273.78125],[590.3333129883,263.1875],[596.0833129883,309.09375],[596.0833129883,291.4375]],\"58\":[[375.375,55.34375],[376.5,55.34375],[375.375,55.34375],[378.75,55.34375],[376.5,55.34375],[384.375,68.9375],[375.375,66.21875],[386.625,90.6875],[374.25,85.25],[386.625,109.71875],[373.125,101.5625],[383.25,104.28125],[377.625,101.5625],[384.375,128.75],[377.625,134.1875],[386.625,147.78125],[379.875,164.09375]],\"59\":[[565.2291870117,18.125],[565.2291870117,15.859375],[563.9583129883,15.859375],[567.7708129883,15.859375],[561.4166870117,15.859375],[571.5833129883,27.1875],[560.1458129883,27.1875],[574.125,45.3125],[557.6041870117,43.046875],[575.3958129883,61.171875],[553.7916870117,45.3125],[569.0416870117,63.4375],[561.4166870117,63.4375],[566.5,88.359375],[563.9583129883,88.359375],[565.2291870117,115.546875],[565.2291870117,111.015625]],\"60\":[[526.5208129883,8.25],[527.5416870117,6.1875],[525.5,6.1875],[529.5833129883,6.1875],[523.4583129883,6.1875],[531.625,20.625],[520.3958129883,22.6875],[532.6458129883,39.1875],[518.3541870117,41.25],[533.6666870117,55.6875],[523.4583129883,41.25],[529.5833129883,57.75],[523.4583129883,59.8125],[529.5833129883,82.5],[523.4583129883,82.5],[527.5416870117,96.9375],[524.4791870117,105.1875]],\"61\":[[469.4583435059,68.796875],[466.5416564941,68.796875],[470.9166564941,65.8125],[465.0833435059,68.796875],[472.375,68.796875],[460.7083435059,83.71875],[475.2916564941,83.71875],[457.7916564941,107.59375],[476.75,110.578125],[456.3333435059,122.515625],[478.2083129883,122.515625],[465.0833435059,122.515625],[472.375,119.53125],[465.0833435059,155.34375],[470.9166564941,146.390625],[465.0833435059,182.203125],[470.9166564941,170.265625]],\"62\":[[471.9166870117,390.15625],[471.9166870117,387.75],[467.3333129883,387.75],[476.5,387.75],[453.5833435059,385.34375],[467.3333129883,392.5625],[432.9583435059,407.0],[474.2083129883,414.21875],[416.9166564941,450.3125],[481.0833129883,443.09375],[430.6666564941,479.1875],[455.875,455.125],[430.6666564941,457.53125],[455.875,476.78125],[437.5416564941,479.1875],[465.0416870117,380.53125],[469.625,387.75]],\"63\":[[353.0,42.0],[353.9583435059,36.0],[353.0,39.0],[354.9166564941,39.0],[351.0833435059,39.0],[357.7916564941,51.0],[349.1666564941,54.0],[357.7916564941,84.0],[347.25,78.0],[348.2083435059,102.0],[349.1666564941,99.0],[352.0416564941,96.0],[353.0,96.0],[355.875,111.0],[355.875,114.0],[361.625,162.0],[361.625,162.0]],\"64\":[[490.5625,12.1875],[491.625,8.125],[489.5,8.125],[493.75,6.09375],[487.375,6.09375],[495.875,20.3125],[484.1875,20.3125],[498.0,38.59375],[482.0625,38.59375],[498.0,54.84375],[481.0,52.8125],[493.75,56.875],[486.3125,54.84375],[491.625,83.28125],[487.375,83.28125],[488.4375,107.65625],[487.375,109.6875]],\"65\":[[531.5625,25.953125],[532.625,23.59375],[530.5,23.59375],[533.6875,23.59375],[528.375,21.234375],[536.875,37.75],[525.1875,37.75],[537.9375,56.625],[522.0,56.625],[537.9375,66.0625],[526.25,56.625],[533.6875,75.5],[527.3125,75.5],[532.625,99.09375],[527.3125,96.734375],[530.5,122.6875],[527.3125,115.609375]],\"66\":[[493.0,25.953125],[494.0416870117,23.59375],[491.9583129883,23.59375],[495.0833129883,21.234375],[490.9166870117,21.234375],[497.1666870117,33.03125],[487.7916870117,35.390625],[499.25,51.90625],[486.75,56.625],[501.3333129883,68.421875],[485.7083435059,73.140625],[497.1666870117,70.78125],[489.875,70.78125],[497.1666870117,96.734375],[490.9166870117,96.734375],[496.125,117.96875],[491.9583129883,120.328125]],\"67\":[[410.7708435059,66.625],[411.9166564941,63.9375],[411.9166564941,66.625],[414.2083435059,63.9375],[410.7708435059,63.9375],[418.7916564941,74.6875],[411.9166564941,74.6875],[422.2291564941,96.1875],[409.625,88.125],[423.375,112.3125],[409.625,106.9375],[417.6458435059,112.3125],[414.2083435059,109.625],[418.7916564941,141.875],[415.3541564941,136.5],[419.9375,168.75],[417.6458435059,158.0]],\"68\":[[468.0,63.375],[463.0,60.5],[468.0,60.5],[463.0,60.5],[468.0,60.5],[461.75,77.75],[473.0,77.75],[459.25,100.75],[475.5,100.75],[459.25,120.875],[474.25,109.375],[464.25,115.125],[470.5,118.0],[464.25,135.25],[470.5,143.875],[463.0,143.875],[469.25,172.625]],\"69\":[[565.4375,35.859375],[566.5,33.46875],[564.375,33.46875],[567.5625,31.078125],[563.3125,31.078125],[570.75,40.640625],[561.1875,40.640625],[571.8125,62.15625],[560.125,57.375],[571.8125,78.890625],[559.0625,69.328125],[568.625,78.890625],[562.25,76.5],[567.5625,102.796875],[562.25,102.796875],[565.4375,124.3125],[561.1875,121.921875]],\"70\":[[586.9166870117,198.375],[588.8333129883,195.0625],[585.0,191.75],[592.6666870117,195.0625],[581.1666870117,195.0625],[596.5,211.625],[577.3333129883,208.3125],[600.3333129883,241.4375],[571.5833129883,231.5],[600.3333129883,267.9375],[567.75,251.375],[590.75,258.0],[579.25,258.0],[590.75,291.125],[575.4166870117,287.8125],[586.9166870117,317.625],[579.25,314.3125]],\"71\":[[344.4583435059,55.359375],[345.4375,52.5625],[343.4791564941,52.5625],[346.4166564941,52.5625],[341.5208435059,52.5625],[349.3541564941,66.546875],[339.5625,66.546875],[352.2916564941,83.328125],[336.625,86.125],[336.625,97.3125],[336.625,100.109375],[347.3958435059,105.703125],[341.5208435059,105.703125],[347.3958435059,136.46875],[340.5416564941,133.671875],[347.3958435059,161.640625],[342.5,158.84375]],\"72\":[[364.1666564941,71.0625],[365.3333435059,71.0625],[364.1666564941,71.0625],[367.6666564941,71.0625],[367.6666564941,68.140625],[372.3333435059,85.671875],[364.1666564941,82.75],[375.8333435059,106.125],[363.0,103.203125],[375.8333435059,126.578125],[361.8333435059,117.8125],[371.1666564941,120.734375],[366.5,120.734375],[371.1666564941,155.796875],[367.6666564941,147.03125],[371.1666564941,187.9375],[372.3333435059,167.484375]],\"73\":[[497.5625,419.546875],[499.7916870117,415.640625],[493.1041870117,417.59375],[504.25,421.5],[477.5,413.6875],[497.5625,419.546875],[455.2083435059,435.171875],[504.25,435.171875],[452.9791564941,480.09375],[510.9375,458.609375],[513.1666870117,466.421875],[495.3333129883,468.375],[477.5,480.09375],[486.4166870117,423.453125],[441.8333435059,444.9375],[488.6458129883,415.640625],[486.4166870117,421.5]],\"74\":[[550.0416870117,37.765625],[560.3541870117,48.328125],[548.8958129883,35.125],[561.5,48.328125],[544.3125,35.125],[564.9375,56.25],[548.8958129883,56.25],[567.2291870117,80.015625],[551.1875,77.375],[568.375,98.5],[552.3333129883,95.859375],[562.6458129883,101.140625],[543.1666870117,106.421875],[544.3125,130.1875],[556.9166870117,127.546875],[558.0625,146.03125],[558.0625,146.03125]],\"75\":[[451.4375,52.3125],[451.4375,52.3125],[456.8541564941,49.703125],[451.4375,52.3125],[456.8541564941,49.703125],[448.7291564941,67.96875],[462.2708435059,67.96875],[444.6666564941,83.625],[466.3333435059,91.453125],[448.7291564941,73.1875],[466.3333435059,107.109375],[452.7916564941,107.109375],[459.5625,104.5],[454.1458435059,130.59375],[459.5625,125.375],[455.5,154.078125],[459.5625,148.859375]],\"76\":[[402.9791564941,80.328125],[404.0833435059,77.6875],[402.9791564941,77.6875],[406.2916564941,77.6875],[410.7083435059,159.546875],[409.6041564941,90.890625],[404.0833435059,90.890625],[414.0208435059,112.015625],[402.9791564941,106.734375],[412.9166564941,133.140625],[401.875,125.21875],[409.6041564941,127.859375],[405.1875,125.21875],[409.6041564941,154.265625],[402.9791564941,148.984375],[410.7083435059,180.671875],[409.6041564941,162.1875]],\"77\":[[499.0,42.3125],[500.0416870117,39.75],[497.9583129883,39.75],[501.0833129883,39.75],[496.9166870117,39.75],[503.1666870117,50.0],[492.75,52.5625],[504.2083129883,73.0625],[492.75,73.0625],[504.2083129883,91.0],[492.75,91.0],[501.0833129883,88.4375],[494.8333129883,88.4375],[501.0833129883,116.625],[494.8333129883,108.9375],[501.0833129883,144.8125],[495.875,126.875]],\"78\":[[556.5,222.34375],[558.5625,218.890625],[554.4375,218.890625],[562.6875,222.34375],[552.375,218.890625],[568.875,239.609375],[548.25,232.703125],[573.0,267.234375],[542.0625,256.875],[570.9375,291.40625],[537.9375,281.046875],[564.75,287.953125],[550.3125,284.5],[564.75,325.9375],[548.25,322.484375],[566.8125,332.84375],[550.3125,350.109375]],\"79\":[[352.625,87.765625],[353.7708435059,87.765625],[353.7708435059,84.9375],[357.2083435059,87.765625],[354.9166564941,93.421875],[362.9375,104.734375],[353.7708435059,99.078125],[365.2291564941,130.1875],[352.625,116.046875],[362.9375,149.984375],[348.0416564941,76.453125],[360.6458435059,138.671875],[354.9166564941,135.84375],[361.7916564941,166.953125],[354.9166564941,169.78125],[362.9375,198.0625],[358.3541564941,198.0625]],\"80\":[[530.0,43.515625],[531.0,40.9375],[530.0,40.9375],[533.0,40.9375],[528.0,40.9375],[535.0,53.828125],[525.0,53.828125],[535.0,77.03125],[524.0,74.453125],[534.0,92.5],[529.0,74.453125],[533.0,95.078125],[528.0,92.5],[529.0,115.703125],[527.0,115.703125],[528.0,144.0625],[528.0,144.0625]],\"81\":[[329.5,73.5625],[329.5,70.515625],[327.375,70.515625],[331.625,189.34375],[327.375,73.5625],[333.75,85.75],[325.25,88.796875],[336.9375,113.171875],[323.125,119.265625],[325.25,131.453125],[325.25,131.453125],[344.375,91.84375],[327.375,131.453125],[336.9375,174.109375],[335.875,143.640625],[331.625,189.34375],[331.625,192.390625]],\"82\":[[544.9583129883,448.25],[549.1666870117,444.125],[538.6458129883,445.5],[553.375,440.0],[519.7083129883,442.75],[544.9583129883,453.75],[496.5625,456.5],[549.1666870117,471.625],[488.1458129883,481.25],[561.7916870117,481.25],[544.9583129883,444.125],[551.2708129883,477.125],[515.5,445.5],[521.8125,441.375],[519.7083129883,441.375],[534.4375,446.875],[542.8541870117,444.125]],\"83\":[[452.3958435059,39.296875],[451.2916564941,39.296875],[453.5,36.8125],[451.2916564941,36.8125],[455.7083435059,36.8125],[449.0833435059,49.234375],[460.125,51.71875],[445.7708435059,64.140625],[461.2291564941,71.59375],[451.2916564941,61.65625],[460.125,79.046875],[451.2916564941,81.53125],[456.8125,81.53125],[451.2916564941,108.859375],[456.8125,108.859375],[452.3958435059,136.1875],[455.7083435059,133.703125]],\"84\":[[533.7083129883,50.5],[532.6041870117,47.875],[533.7083129883,50.5],[529.2916870117,47.875],[534.8125,47.875],[524.875,66.25],[537.0208129883,66.25],[523.7708129883,87.25],[535.9166870117,89.875],[522.6666870117,105.625],[537.0208129883,113.5],[528.1875,100.375],[533.7083129883,100.375],[529.2916870117,124.0],[534.8125,126.625],[529.2916870117,147.625],[533.7083129883,160.75]],\"85\":[[492.5,51.15625],[492.5,48.375],[491.3541870117,48.375],[494.7916870117,48.375],[491.3541870117,48.375],[497.0833129883,62.28125],[486.7708129883,62.28125],[498.2291870117,87.3125],[485.625,84.53125],[499.375,104.0],[484.4791564941,101.21875],[494.7916870117,101.21875],[489.0625,101.21875],[495.9375,126.25],[489.0625,134.59375],[497.0833129883,145.71875],[489.0625,162.40625]],\"86\":[[534.875,250.6875],[539.5,242.875],[534.875,242.875],[541.8125,246.78125],[532.5625,242.875],[548.75,258.5],[527.9375,254.59375],[555.6875,285.84375],[521.0,281.9375],[558.0,313.1875],[518.6875,309.28125],[544.125,313.1875],[534.875,313.1875],[539.5,360.0625],[534.875,356.15625],[530.25,387.40625],[530.25,387.40625]],\"87\":[[392.5625,87.78125],[393.75,85.0625],[392.5625,85.0625],[396.125,82.34375],[396.125,82.34375],[400.875,98.65625],[394.9375,98.65625],[403.25,120.40625],[393.75,117.6875],[399.6875,142.15625],[391.375,131.28125],[398.5,128.5625],[396.125,125.84375],[402.0625,150.3125],[393.75,155.75],[404.4375,180.21875],[394.9375,188.375]],\"88\":[[552.4375,50.453125],[551.2083129883,47.625],[551.2083129883,47.625],[563.5,58.9375],[549.9791870117,47.625],[565.9583129883,70.25],[554.8958129883,70.25],[568.4166870117,92.875],[554.8958129883,92.875],[570.875,109.84375],[553.6666870117,115.5],[563.5,115.5],[563.5,112.671875],[561.0416870117,140.953125],[552.4375,135.296875],[549.9791870117,163.578125],[549.9791870117,166.40625]],\"89\":[[346.3333435059,94.796875],[347.6666564941,91.8125],[346.3333435059,91.8125],[351.6666564941,94.796875],[347.6666564941,91.8125],[357.0,106.734375],[343.6666564941,106.734375],[359.6666564941,130.609375],[342.3333435059,127.625],[362.3333435059,151.5],[342.3333435059,151.5],[355.6666564941,151.5],[347.6666564941,151.5],[357.0,181.34375],[350.3333435059,181.34375],[358.3333435059,208.203125],[353.0,205.21875]],\"90\":[[321.2291564941,90.375],[321.2291564941,84.3125],[318.6875,87.34375],[333.9375,93.40625],[317.4166564941,90.375],[326.3125,105.53125],[316.1458435059,105.53125],[326.3125,132.8125],[323.7708435059,132.8125],[325.0416564941,151.0],[325.0416564941,151.0],[325.0416564941,147.96875],[321.2291564941,151.0],[326.3125,187.375],[326.3125,181.3125],[335.2083435059,208.59375],[326.3125,184.34375]],\"91\":[[583.25,457.28125],[585.5625,456.390625],[578.625,456.390625],[583.25,457.28125],[555.5,459.0625],[592.5,467.96875],[532.375,463.515625],[601.75,482.21875],[502.3125,476.875],[553.1875,459.953125],[502.3125,478.65625],[553.1875,478.65625],[534.6875,483.109375],[555.5,460.84375],[562.4375,464.40625],[560.125,459.0625],[502.3125,471.53125]],\"92\":[[445.1666564941,20.953125],[445.1666564941,25.609375],[451.0,18.625],[445.1666564941,20.953125],[451.0,20.953125],[444.0,34.921875],[455.6666564941,34.921875],[441.6666564941,51.21875],[460.3333435059,58.203125],[445.1666564941,44.234375],[454.5,51.21875],[446.3333435059,79.15625],[454.5,81.484375],[444.0,69.84375],[453.3333435059,102.4375],[446.3333435059,107.09375],[454.5,123.390625]],\"93\":[[379.125,79.734375],[381.5833435059,77.0625],[379.125,77.0625],[385.2708435059,77.0625],[379.125,77.0625],[388.9583435059,93.09375],[377.8958435059,93.09375],[393.875,111.796875],[376.6666564941,109.125],[392.6458435059,133.171875],[377.8958435059,127.828125],[388.9583435059,130.5],[382.8125,130.5],[390.1875,157.21875],[385.2708435059,157.21875],[393.875,181.265625],[388.9583435059,181.265625]],\"94\":[[483.0,51.65625],[484.25,51.65625],[481.75,48.6875],[486.75,51.65625],[480.5,48.6875],[488.0,66.5],[478.0,66.5],[490.5,90.25],[475.5,90.25],[489.25,111.03125],[473.0,108.0625],[485.5,108.0625],[480.5,111.03125],[484.25,140.71875],[481.75,140.71875],[483.0,173.375],[484.25,152.59375]],\"95\":[[313.0,92.875],[314.4166564941,89.5],[310.1666564941,89.5],[315.8333435059,89.5],[308.75,89.5],[318.6666564941,106.375],[305.9166564941,109.75],[322.9166564941,133.375],[304.5,133.375],[322.9166564941,146.875],[304.5,150.25],[317.25,153.625],[310.1666564941,153.625],[320.0833435059,184.0],[310.1666564941,190.75],[320.0833435059,211.0],[311.5833435059,224.5]],\"96\":[[563.0,70.171875],[564.125,67.3125],[561.875,67.3125],[566.375,67.3125],[559.625,67.3125],[567.5,81.609375],[557.375,81.609375],[568.625,104.484375],[556.25,104.484375],[567.5,124.5],[555.125,124.5],[564.125,124.5],[558.5,121.640625],[561.875,153.09375],[559.625,153.09375],[559.625,175.96875],[559.625,181.6875]],\"97\":[[513.5,269.34375],[515.6875,265.390625],[511.3125,265.390625],[520.0625,265.390625],[509.125,261.4375],[526.625,281.203125],[506.9375,273.296875],[526.625,316.78125],[500.375,300.96875],[524.4375,344.453125],[496.0,324.6875],[520.0625,336.546875],[506.9375,332.59375],[520.0625,368.171875],[504.75,376.078125],[517.875,383.984375],[498.1875,419.5625]],\"98\":[[358.5,99.390625],[359.7291564941,96.4375],[357.2708435059,96.4375],[360.9583435059,93.484375],[354.8125,96.4375],[362.1875,108.25],[352.3541564941,114.15625],[363.4166564941,128.921875],[352.3541564941,140.734375],[365.875,149.59375],[354.8125,155.5],[360.9583435059,146.640625],[354.8125,149.59375],[362.1875,185.03125],[360.9583435059,185.03125],[358.5,211.609375],[356.0416564941,214.5625]],\"99\":[[538.3333129883,55.0],[539.6666870117,52.0],[537.0,52.0],[541.0,52.0],[534.3333129883,52.0],[543.6666870117,70.0],[530.3333129883,70.0],[543.6666870117,91.0],[527.6666870117,94.0],[547.6666870117,76.0],[533.0,94.0],[545.0,115.0],[534.3333129883,115.0],[546.3333129883,142.0],[534.3333129883,139.0],[534.3333129883,163.0],[533.0,166.0]]},\"confidences\":{\"0\":[[0.0150153972],[0.0166315492],[0.014266843],[0.90480268],[0.8671654463],[0.8553804755],[0.8459371924],[0.8578199744],[0.8097881675],[0.3452049792],[0.7178892493],[0.5586058497],[0.6241006255],[0.5749081373],[0.4996139705],[0.8366793394],[0.2387447059]],\"1\":[[0.5421698689],[0.4973727167],[0.5392796993],[0.3482079208],[0.5730258226],[0.8034726977],[0.8059111238],[0.8459157348],[0.7802795768],[0.8714576364],[0.8093458414],[0.7055396438],[0.7049397826],[0.5557048321],[0.7414289713],[0.7122840881],[0.7965415716]],\"2\":[[0.8332034945],[0.9014892578],[0.8185026646],[0.6769462228],[0.5064809918],[0.7589527965],[0.7662339211],[0.800989449],[0.7663338184],[0.8115350604],[0.7938713431],[0.6721792817],[0.6526498795],[0.8666241765],[0.5371960998],[0.6372277737],[0.5135959983]],\"3\":[[0.0048622992],[0.0018599372],[0.0024817374],[0.0057929773],[0.0049143564],[0.3768490255],[0.147989735],[0.7634152174],[0.7095158696],[0.8139795065],[0.6992505193],[0.629180491],[0.5820295215],[0.6993117332],[0.7631930113],[0.6557770967],[0.4606105089]],\"4\":[[0.0012897616],[0.0018837501],[0.0043191016],[0.007565442],[0.0056078262],[0.0040241745],[0.0036658824],[0.1752231419],[0.2263014317],[0.7656214237],[0.5926937461],[0.5445911884],[0.5888078809],[0.7478337884],[0.6836134195],[0.7057988048],[0.6771100163]],\"5\":[[0.0031106819],[0.0034130786],[0.0072229356],[0.005110791],[0.0099198334],[0.0095911985],[0.0365080498],[0.3389700353],[0.2104095221],[0.6782439351],[0.2077045739],[0.4963661432],[0.4658751786],[0.7331120372],[0.6810231209],[0.6330000758],[0.4499024153]],\"6\":[[0.7852206826],[0.8344535232],[0.7768663764],[0.4723820686],[0.6343725324],[0.7795536518],[0.7093073726],[0.7867788076],[0.5963016152],[0.7802278399],[0.8163892031],[0.6641452909],[0.5739392638],[0.8185804486],[0.1859622002],[0.8565051556],[0.2940517366]],\"7\":[[0.0015752892],[0.0028634218],[0.0054309098],[0.0065892814],[0.0034535287],[0.0015098236],[0.005114174],[0.0022586451],[0.0030401519],[0.0024143637],[0.004381211],[0.0381839015],[0.0371198878],[0.4882330596],[0.4291966259],[0.4030598402],[0.412982583]],\"8\":[[0.2944512963],[0.2235851586],[0.2713182569],[0.3085916638],[0.6737495661],[0.8565475345],[0.8106419444],[0.8466503024],[0.8835456371],[0.8583804369],[0.8780817389],[0.7236067653],[0.7014729977],[0.695507884],[0.6666992903],[0.7844943404],[0.8571572304]],\"9\":[[0.0122997798],[0.0113843624],[0.0111162718],[0.8152393699],[0.7950268388],[0.8586186171],[0.847094059],[0.8599503636],[0.7851109505],[0.3652466536],[0.3228545785],[0.6457289457],[0.6142436862],[0.627943933],[0.6996327639],[0.7673916221],[0.8392577171]],\"10\":[[0.8194289207],[0.7874860168],[0.8133045435],[0.6656504273],[0.7068403363],[0.7873745561],[0.7681744695],[0.7776535749],[0.7341789007],[0.769205749],[0.760640502],[0.6496837139],[0.632756412],[0.5172772408],[0.7065008879],[0.6681598425],[0.6500017047]],\"11\":[[0.306597352],[0.0855573937],[0.0735053793],[0.2267409712],[0.0765124857],[0.7263660431],[0.7598755956],[0.7345333695],[0.7523434162],[0.7329262495],[0.7719758153],[0.580049336],[0.6189838648],[0.5046610236],[0.6871773601],[0.5737407207],[0.7611748576]],\"12\":[[0.8111208677],[0.9178135991],[0.842677772],[0.6076533794],[0.5293150544],[0.7698087692],[0.7462921739],[0.7401428819],[0.682261169],[0.8291283846],[0.7600166798],[0.6478354335],[0.626054585],[0.6795659661],[0.4763096273],[0.6833288074],[0.501424849]],\"13\":[[0.0046849833],[0.0046570036],[0.0082728155],[0.0160672385],[0.0083576534],[0.7688248754],[0.7895694971],[0.824242413],[0.6407849789],[0.8034396172],[0.6191676259],[0.6350657344],[0.7214643955],[0.763071835],[0.8074169159],[0.7045104504],[0.7673193812]],\"14\":[[0.0031898115],[0.0028013121],[0.0042721708],[0.0087633291],[0.0050824112],[0.0038668343],[0.0025490548],[0.0279129911],[0.0031851407],[0.5357425809],[0.3635217547],[0.4515796304],[0.4796067774],[0.6155722737],[0.5972656012],[0.6538558006],[0.5362716317]],\"15\":[[0.0025519822],[0.0051013986],[0.0034899653],[0.0075985035],[0.0079144314],[0.0265304148],[0.0308523308],[0.5971977711],[0.7149682045],[0.7073876858],[0.7354596257],[0.5239177942],[0.5681767464],[0.724347353],[0.7785275578],[0.7127762437],[0.6912229657]],\"16\":[[0.0020203495],[0.0026125673],[0.0035034982],[0.0106199402],[0.0039316299],[0.0025759018],[0.0025741819],[0.0035172994],[0.002913743],[0.4272921085],[0.0461377017],[0.3123288751],[0.2688728273],[0.6296406388],[0.6493179798],[0.4261832535],[0.54145509]],\"17\":[[0.1632423699],[0.1192784905],[0.1214554012],[0.1195461079],[0.4583936334],[0.8058677316],[0.796513617],[0.8064561486],[0.7930915952],[0.8406538963],[0.8635369539],[0.6979900599],[0.6963743567],[0.5476108193],[0.507943213],[0.1608284861],[0.3246124089]],\"18\":[[0.637632668],[0.667294085],[0.6943052411],[0.6586147547],[0.098116219],[0.7217019796],[0.6985231638],[0.7550443411],[0.6893520355],[0.7758514881],[0.7120522261],[0.6654162407],[0.6065009832],[0.7852565646],[0.690384388],[0.7007587552],[0.6260374784]],\"19\":[[0.0105443718],[0.0130533101],[0.007261896],[0.904294014],[0.7355582118],[0.8140016198],[0.8182485104],[0.8199124932],[0.8180660009],[0.3004391193],[0.6803593636],[0.5446019173],[0.6188488007],[0.6443661451],[0.5937863588],[0.8090777397],[0.7815573215]],\"20\":[[0.827578485],[0.7673364878],[0.3399446309],[0.7529810667],[0.0118701793],[0.7997016311],[0.7991446853],[0.7982951999],[0.731885612],[0.919526279],[0.7695682645],[0.7385695577],[0.6929044724],[0.802297771],[0.640170455],[0.7463188171],[0.3603168726]],\"21\":[[0.8337817788],[0.8430688381],[0.889341414],[0.6555022597],[0.6737611294],[0.7305125594],[0.7216286063],[0.7405982614],[0.7378542423],[0.8023867607],[0.8290315866],[0.6463204622],[0.6226810217],[0.3511783183],[0.3311742246],[0.0091498913],[0.0058714147]],\"22\":[[0.0036030309],[0.0018403607],[0.0096464725],[0.0072820764],[0.0035457169],[0.0066888793],[0.0032076722],[0.3648023605],[0.3086117208],[0.4690290391],[0.0316203609],[0.3306503296],[0.2960315943],[0.5501286983],[0.6075096726],[0.4347279966],[0.5801904202]],\"23\":[[0.0018176886],[0.0023058082],[0.0108771017],[0.0088625103],[0.0038700958],[0.0022185389],[0.0049658031],[0.0426270738],[0.0143929953],[0.4505052865],[0.0439532287],[0.3556362689],[0.342246592],[0.5782596469],[0.4653176367],[0.5947304964],[0.5666458607]],\"24\":[[0.8648133278],[0.8899084926],[0.8491081595],[0.7186040282],[0.4597411454],[0.8062794805],[0.7767394185],[0.8149849772],[0.7845596075],[0.8410518765],[0.7859791517],[0.5940181613],[0.6059105396],[0.5664767027],[0.6600945592],[0.7679277658],[0.8597871065]],\"25\":[[0.1994499713],[0.1213824674],[0.1527680904],[0.1687972844],[0.3594529629],[0.7400081754],[0.7839432955],[0.4632472694],[0.8248795867],[0.299439013],[0.7912602425],[0.6941182613],[0.6842754483],[0.6170945764],[0.7213387489],[0.7340000272],[0.7733251452]],\"26\":[[0.0061025186],[0.0054984405],[0.0071890862],[0.0647258312],[0.4439624846],[0.1827705204],[0.4468229711],[0.1609244347],[0.4166344106],[0.0419990011],[0.3781323731],[0.1700164974],[0.2959533632],[0.0094881281],[0.0446032248],[0.0347467549],[0.1822625995]],\"27\":[[0.0115017379],[0.0077212499],[0.0109796179],[0.9094235301],[0.7669231892],[0.8739290237],[0.883146584],[0.8814764023],[0.8535448313],[0.070855163],[0.7594154477],[0.6783286333],[0.6287729144],[0.6051166654],[0.6135604978],[0.7554751039],[0.3240038455]],\"28\":[[0.8351795673],[0.8912867904],[0.8339811563],[0.6632323265],[0.5560387373],[0.7543893456],[0.7741407156],[0.7551168799],[0.7161306143],[0.8228201866],[0.7159850597],[0.6576163769],[0.626473546],[0.6354948878],[0.5821097493],[0.7465560436],[0.6664951444]],\"29\":[[0.2977836132],[0.2143299431],[0.2780720592],[0.0146224052],[0.7188642025],[0.7608435154],[0.6273549199],[0.7750250101],[0.7752494812],[0.8333832622],[0.8036810756],[0.5787405968],[0.578699708],[0.2871638834],[0.1874182522],[0.0124609368],[0.0090849604]],\"30\":[[0.8124783635],[0.8996514678],[0.8803128004],[0.6598209739],[0.3622948527],[0.6558402777],[0.6606314182],[0.5120978951],[0.575345695],[0.0177299567],[0.0164584033],[0.1151105165],[0.0847084671],[0.0028557528],[0.0041640503],[0.0069223605],[0.0047932523]],\"31\":[[0.0220614225],[0.0456837341],[0.0235538576],[0.0180371813],[0.0204943605],[0.0991498455],[0.061467614],[0.0112338038],[0.0196966231],[0.0462681949],[0.0419930182],[0.03138607],[0.0199701246],[0.0456090234],[0.0294586401],[0.0465920642],[0.102353856]],\"32\":[[0.7691046596],[0.7898868322],[0.4546638429],[0.8337917328],[0.0204900205],[0.7405055165],[0.7684596181],[0.7647497654],[0.8451111317],[0.8241805434],[0.7265254259],[0.6805843711],[0.7439710498],[0.6794742346],[0.8068622947],[0.5911866426],[0.6658012271]],\"33\":[[0.773129344],[0.775644958],[0.3013014793],[0.8038851619],[0.0107303448],[0.8075799942],[0.8011852503],[0.8054991961],[0.7413911819],[0.7729657292],[0.7085672617],[0.7040172219],[0.7063313127],[0.7002143264],[0.8574335575],[0.7606940269],[0.7445238829]],\"34\":[[0.0039220871],[0.0037317385],[0.0040460038],[0.0061896741],[0.0045457785],[0.2658049464],[0.1432790011],[0.682766974],[0.5473399162],[0.7562217116],[0.2199624777],[0.5959349275],[0.5598137379],[0.655297935],[0.5546135306],[0.6073018909],[0.581662178]],\"35\":[[0.1986833066],[0.2592187226],[0.0887193978],[0.5551646948],[0.0193117596],[0.5641773343],[0.187456429],[0.5735376477],[0.0175693762],[0.4464730918],[0.0288236402],[0.2975904942],[0.2171374261],[0.0145485122],[0.0048465324],[0.0165642407],[0.0155258141]],\"36\":[[0.0041714944],[0.0051541296],[0.0093017668],[0.0069931224],[0.008024253],[0.0151624735],[0.0142333629],[0.4335582554],[0.3346118033],[0.6492399573],[0.5296323895],[0.4928864837],[0.4803618789],[0.6934459805],[0.7245566249],[0.7221324444],[0.6811053157]],\"37\":[[0.0060676429],[0.0039576804],[0.0174054932],[0.8099034429],[0.7120543122],[0.8680375814],[0.8187032938],[0.8571689129],[0.8871065378],[0.7901262641],[0.1721104234],[0.5436791778],[0.5632457137],[0.413749516],[0.5698854923],[0.4597293437],[0.8072800636]],\"38\":[[0.4000579119],[0.3611125648],[0.4094644189],[0.0086036632],[0.6729232073],[0.5083208084],[0.5653550625],[0.6477714777],[0.7100431919],[0.8173797727],[0.7067584991],[0.3347757459],[0.316465199],[0.0295030717],[0.0090213092],[0.0082920287],[0.0116117587]],\"39\":[[0.5958456993],[0.6042966247],[0.2286754847],[0.7004961371],[0.0177915078],[0.7314158678],[0.7859460115],[0.7548133135],[0.7784751654],[0.7539281249],[0.7560116649],[0.7172550559],[0.7466783524],[0.7982379794],[0.7675874829],[0.4721324146],[0.7631931901]],\"40\":[[0.8107968569],[0.9105218053],[0.8154915571],[0.5301637053],[0.6994325519],[0.7605329156],[0.7660160065],[0.7920421958],[0.7444006801],[0.8380796909],[0.8107824922],[0.6706594825],[0.6506735086],[0.7112960219],[0.6043201089],[0.7950481772],[0.4941381812]],\"41\":[[0.0605242252],[0.027270047],[0.0139782177],[0.0365446284],[0.0215838626],[0.7580496669],[0.7660416961],[0.8097980618],[0.7404739261],[0.8420092463],[0.7693518996],[0.6517944336],[0.6964794397],[0.7673513293],[0.7341920733],[0.7242311835],[0.6625144482]],\"42\":[[0.7384861112],[0.7437133193],[0.3483511806],[0.7938589454],[0.0108596031],[0.7591861486],[0.7388865948],[0.7411309481],[0.6614800096],[0.6485677361],[0.6904020309],[0.6652955413],[0.6361162066],[0.7765722275],[0.7076720595],[0.6548646688],[0.742066741]],\"43\":[[0.1637793034],[0.2239162773],[0.2089840919],[0.1102451533],[0.0805617124],[0.2708598077],[0.1853941083],[0.1857549846],[0.2275833189],[0.0836067274],[0.2298996747],[0.1822548509],[0.1441541612],[0.2550193965],[0.215210706],[0.331556648],[0.230994612]],\"44\":[[0.0034556193],[0.0053039747],[0.005918052],[0.0060395161],[0.0080555733],[0.4546672702],[0.174929902],[0.8291156292],[0.7410345078],[0.8020806909],[0.7429265976],[0.6244826913],[0.6422759891],[0.6350300908],[0.7192000151],[0.6963326931],[0.6656090021]],\"45\":[[0.7757253051],[0.7720373869],[0.8008856177],[0.4397653043],[0.2378753871],[0.3673011959],[0.5519217849],[0.0789773837],[0.1023050547],[0.0065705548],[0.0050552087],[0.0103329848],[0.0071261488],[0.0056349817],[0.0015638527],[0.0071328618],[0.0030319721]],\"46\":[[0.022105962],[0.006094662],[0.0080602895],[0.0073651862],[0.0099356333],[0.6780472398],[0.6745610833],[0.8053106666],[0.4936126173],[0.8193801045],[0.7724746466],[0.6811967492],[0.6428266168],[0.8050240874],[0.775200367],[0.6636663079],[0.7690481544]],\"47\":[[0.8414500356],[0.9259701967],[0.892031908],[0.5934365392],[0.6425543427],[0.7172999978],[0.723426342],[0.7959882617],[0.7111503482],[0.8566606641],[0.813374579],[0.6196328402],[0.6588183045],[0.5707471967],[0.5303326845],[0.5948897004],[0.4556604028]],\"48\":[[0.5666499734],[0.5131493807],[0.5979281664],[0.0053021591],[0.5114229918],[0.6080750823],[0.4843310416],[0.7245264053],[0.6457177401],[0.8154037595],[0.5680392385],[0.2936500609],[0.2382586151],[0.0552186035],[0.0134792458],[0.0156198908],[0.0068723788]],\"49\":[[0.008623193],[0.0055523384],[0.0103090024],[0.8574236631],[0.7508499026],[0.8235657811],[0.8221405149],[0.6724761724],[0.7801331878],[0.5448487401],[0.8153157234],[0.7484695315],[0.7127109766],[0.7211104035],[0.7833562493],[0.8297576308],[0.8062480688]],\"50\":[[0.0638996288],[0.0756035447],[0.0784222707],[0.0488873422],[0.0621040501],[0.2274294198],[0.2275890261],[0.0308238026],[0.0945165902],[0.0397571735],[0.0845048502],[0.0329627357],[0.0379875451],[0.0430896319],[0.1065512449],[0.0695550889],[0.2536467314]],\"51\":[[0.6292263269],[0.6034547091],[0.6386919618],[0.6346567273],[0.2023141086],[0.7549672127],[0.8117453456],[0.7466001511],[0.828808248],[0.8046724796],[0.7925578356],[0.7158482671],[0.655356288],[0.658934176],[0.7765114307],[0.6599048376],[0.774595499]],\"52\":[[0.0302777402],[0.0044152495],[0.0103114415],[0.0127697922],[0.007902774],[0.760294497],[0.7381255627],[0.7193855047],[0.7717297673],[0.7923322916],[0.8112081885],[0.6545799375],[0.6298072934],[0.7257044315],[0.8174165487],[0.7690494657],[0.7482036352]],\"53\":[[0.0070257699],[0.0038097629],[0.0040762359],[0.0064180028],[0.0284522399],[0.7568129897],[0.8165698647],[0.7765130997],[0.7594810724],[0.805529058],[0.7532167435],[0.6323574185],[0.6312483549],[0.7289431095],[0.7454861999],[0.6782300472],[0.5364123583]],\"54\":[[0.3122320175],[0.4256069958],[0.1995040923],[0.5413440466],[0.0524292327],[0.5985847116],[0.5856936574],[0.7597370744],[0.3452626169],[0.6889153123],[0.2369150668],[0.6109532118],[0.5529589057],[0.801507771],[0.6885174513],[0.8041878939],[0.435936451]],\"55\":[[0.324567765],[0.3500306904],[0.1605299115],[0.5057831407],[0.0641616806],[0.7913867235],[0.6811288595],[0.7287961841],[0.7763620019],[0.4376679957],[0.8255637288],[0.5949354768],[0.6034950614],[0.7137551904],[0.5374184251],[0.7047327161],[0.2212637961]],\"56\":[[0.3625400364],[0.3818620741],[0.1223457307],[0.6025934219],[0.0357062034],[0.6946709156],[0.645968914],[0.804166913],[0.8009793162],[0.8100585341],[0.8428285718],[0.5302320719],[0.5327920914],[0.5741171837],[0.6998903155],[0.7430262566],[0.8385326266]],\"57\":[[0.8377848864],[0.8849163651],[0.8782773614],[0.6569347978],[0.6479113698],[0.7466811538],[0.7781511545],[0.7778765559],[0.7549390197],[0.8330591321],[0.780371666],[0.7060506344],[0.672540009],[0.6954146624],[0.2890631855],[0.7333064675],[0.2116745412]],\"58\":[[0.697286725],[0.629543364],[0.2349391878],[0.7552990317],[0.0237050243],[0.8337948918],[0.7660201788],[0.814407289],[0.7187767029],[0.7755414248],[0.7820882201],[0.6937146187],[0.6857076287],[0.7432100177],[0.7927060127],[0.6349548101],[0.8190996647]],\"59\":[[0.3868100047],[0.3911980689],[0.4022526145],[0.2563627064],[0.1556655318],[0.6718207598],[0.6601699591],[0.7528269291],[0.6390029192],[0.8077638745],[0.4825998843],[0.6321772933],[0.5740533471],[0.7279946208],[0.6085364819],[0.6996375322],[0.4902889132]],\"60\":[[0.7912287116],[0.797924459],[0.8268280029],[0.7388290763],[0.8013235331],[0.7968559861],[0.75195539],[0.8288508654],[0.694868803],[0.9017677903],[0.8165556788],[0.7369180918],[0.6671881676],[0.8025676012],[0.7957382202],[0.7375804782],[0.7988783717]],\"61\":[[0.0124195376],[0.0126290629],[0.0239708498],[0.830065608],[0.8639647961],[0.8512265086],[0.7851133943],[0.6759307384],[0.7076244354],[0.8122743368],[0.7037789822],[0.5931665301],[0.5622193217],[0.6748588681],[0.4497505724],[0.8467590809],[0.5428232551]],\"62\":[[0.3870777488],[0.2545390427],[0.3304405808],[0.0071394015],[0.2360872477],[0.4778249562],[0.3188861609],[0.7196160555],[0.3603869081],[0.7952819467],[0.0217899494],[0.3568972349],[0.235199064],[0.0390760042],[0.0059478241],[0.0101918103],[0.0068716616]],\"63\":[[0.049910374],[0.0675267205],[0.0419222489],[0.0252045821],[0.0243657846],[0.1542794853],[0.1463831663],[0.0084177935],[0.0304193627],[0.0134835802],[0.0127605963],[0.0184703413],[0.0162002482],[0.0089637805],[0.0054058535],[0.0286903325],[0.0206594244]],\"64\":[[0.5879794359],[0.6112605929],[0.6020860076],[0.4792672396],[0.6224841475],[0.7352736592],[0.719679296],[0.7289878726],[0.7428556085],[0.8498976827],[0.7139794827],[0.5968033671],[0.5378646255],[0.6894156337],[0.6721498966],[0.4691362977],[0.4282450676]],\"65\":[[0.6984679103],[0.7148955464],[0.6891390085],[0.5805736184],[0.695535481],[0.8075520396],[0.7720496655],[0.7818593979],[0.6229889989],[0.6778761148],[0.7306654453],[0.7391067147],[0.7451685071],[0.7850187421],[0.6739670634],[0.6805738211],[0.6024143696]],\"66\":[[0.5157770514],[0.5147356987],[0.5048051476],[0.3277612627],[0.4639516771],[0.6812422872],[0.6398276091],[0.6342574358],[0.5960298777],[0.7721772194],[0.5215563178],[0.6010287404],[0.5569037199],[0.7715190649],[0.5334116817],[0.6974570751],[0.5967980027]],\"67\":[[0.3698815405],[0.3958500624],[0.1518409699],[0.6109048724],[0.0318500288],[0.787178874],[0.5966742039],[0.7930332422],[0.6313508749],[0.7637041211],[0.7090218663],[0.6030877233],[0.6303620338],[0.7258082032],[0.7415580153],[0.7454402447],[0.714456141]],\"68\":[[0.011610263],[0.0149347568],[0.0150650432],[0.8718140721],[0.7794089317],[0.8584598899],[0.8268116117],[0.7869555354],[0.8257632852],[0.8585571647],[0.4026485384],[0.5155341029],[0.5646300912],[0.3693390787],[0.805429101],[0.5145718455],[0.7837171555]],\"69\":[[0.5512020588],[0.581074357],[0.566211462],[0.5343453288],[0.406924665],[0.6782137156],[0.7159622312],[0.739601016],[0.5882899761],[0.7208282351],[0.4372914732],[0.5919290781],[0.562376678],[0.5405215621],[0.6659260988],[0.5854363441],[0.5198726058]],\"70\":[[0.8864987493],[0.9357345104],[0.9199920893],[0.658308506],[0.4956710041],[0.7354669571],[0.7472871542],[0.8090367317],[0.7730852962],[0.8356814384],[0.8487050533],[0.6396698356],[0.7041733861],[0.6206291318],[0.8484594226],[0.8336173892],[0.8183739781]],\"71\":[[0.2490809113],[0.3021987677],[0.282797724],[0.1605056822],[0.2619287372],[0.3697259724],[0.3480384648],[0.0789690167],[0.2325288653],[0.0420280248],[0.197939977],[0.296099782],[0.2808373868],[0.2364610583],[0.3829895854],[0.4346443117],[0.3489711881]],\"72\":[[0.6341758966],[0.6715662479],[0.2527912557],[0.7260741591],[0.0162401237],[0.7380050421],[0.677126348],[0.8780822754],[0.5375047326],[0.7839040756],[0.6196718216],[0.6578868032],[0.6134949327],[0.7118887305],[0.5528428555],[0.7633853555],[0.506046176]],\"73\":[[0.4244457185],[0.3064281344],[0.427310288],[0.004889797],[0.488604635],[0.3846357167],[0.3821212649],[0.5782368183],[0.0316874459],[0.6877134442],[0.0159745011],[0.1799176931],[0.0495452583],[0.0043094344],[0.00236654],[0.0139292711],[0.0046977107]],\"74\":[[0.2464322299],[0.0424917303],[0.1757395118],[0.0339837074],[0.0998527557],[0.1137204021],[0.0956201926],[0.0659725517],[0.0792859048],[0.0859276354],[0.3011774123],[0.0262756515],[0.0359162465],[0.0373748504],[0.0481873788],[0.0258433893],[0.064998664]],\"75\":[[0.0129109686],[0.0251621157],[0.0165870786],[0.8235628009],[0.7222395539],[0.8182713389],[0.7937986851],[0.8493055701],[0.7407548428],[0.1502071172],[0.6037445664],[0.6293040514],[0.6325893402],[0.6602776647],[0.5953534245],[0.7460190654],[0.5883272886]],\"76\":[[0.3628561497],[0.4172038138],[0.1906342953],[0.5803186297],[0.0229763165],[0.7171669602],[0.5322926641],[0.7214485407],[0.4793145359],[0.7665825486],[0.5450587869],[0.6843404174],[0.6397893429],[0.5829296708],[0.7716813684],[0.7437114716],[0.7369259596]],\"77\":[[0.6922825575],[0.7489067316],[0.7099060416],[0.6764573455],[0.5508924127],[0.7623456717],[0.7363355756],[0.7462826967],[0.7314007282],[0.7152433991],[0.7105950117],[0.6750494838],[0.6083046198],[0.7070273757],[0.542101264],[0.7387226224],[0.7343186736]],\"78\":[[0.8274371028],[0.8699752092],[0.8845511675],[0.5825638771],[0.6496361494],[0.7438281178],[0.7571802735],[0.6578588486],[0.7179691792],[0.6430725455],[0.7561771274],[0.5735837221],[0.6384481788],[0.4680927694],[0.7323738337],[0.6514888406],[0.7929556966]],\"79\":[[0.7015727758],[0.7105479836],[0.0872258395],[0.8379780054],[0.019361414],[0.732376039],[0.6082972884],[0.7593971491],[0.0921706334],[0.8085439205],[0.0546940416],[0.6564867496],[0.6419596076],[0.6879630685],[0.8105763793],[0.7677932978],[0.7871816158]],\"80\":[[0.1207737103],[0.1608197987],[0.1594809443],[0.227327317],[0.1743626297],[0.2786678672],[0.3050728142],[0.1844345927],[0.2107117623],[0.2106550932],[0.18096596],[0.1419281811],[0.1706367284],[0.0485681891],[0.0673958138],[0.0701969489],[0.0705677122]],\"81\":[[0.0270610973],[0.0448347032],[0.040590737],[0.0216143392],[0.0149572846],[0.0329681039],[0.047822047],[0.0091160517],[0.0054300982],[0.0096388794],[0.0129928701],[0.0075668734],[0.0096966652],[0.021790456],[0.0147860339],[0.0297463294],[0.0473526604]],\"82\":[[0.5291402936],[0.4704665244],[0.4725798965],[0.0125472154],[0.7000377774],[0.1468296498],[0.3988641202],[0.0175736882],[0.0130503085],[0.0047148932],[0.0036199936],[0.0061874245],[0.0029453901],[0.004058531],[0.0014767421],[0.0125000942],[0.0038325612]],\"83\":[[0.0284435209],[0.0535761081],[0.0167251285],[0.8648686409],[0.7395997047],[0.7926387787],[0.7698816657],[0.8434864879],[0.4524902701],[0.1450489461],[0.0456498452],[0.5781662464],[0.6597408056],[0.718596518],[0.8102180958],[0.7262790799],[0.7279208899]],\"84\":[[0.0436006896],[0.0489237309],[0.0431897491],[0.6096446514],[0.7235384583],[0.5683891773],[0.6954693794],[0.4358861744],[0.5702108741],[0.4749831557],[0.4976521432],[0.5396636128],[0.5758836865],[0.6459487081],[0.5635879636],[0.4266754687],[0.2446419597]],\"85\":[[0.2473440021],[0.2570340335],[0.2620434463],[0.41837731],[0.3356903493],[0.5582831502],[0.6652306318],[0.6348552704],[0.6577110887],[0.5673368573],[0.6602377892],[0.5936231017],[0.6046942472],[0.5088287592],[0.742849052],[0.645519495],[0.7315742373]],\"86\":[[0.7732844353],[0.7408835292],[0.7962414622],[0.554449439],[0.406674087],[0.7074890733],[0.7249150276],[0.6947955489],[0.7283635139],[0.7569191456],[0.7939466834],[0.5669646263],[0.5767821074],[0.6327263117],[0.396844089],[0.5770110488],[0.3072769046]],\"87\":[[0.2488033921],[0.2582700551],[0.0857499912],[0.5011077523],[0.0147959888],[0.5927023292],[0.4895175993],[0.6638239026],[0.1044455543],[0.8090142012],[0.2225123644],[0.3579217494],[0.2803858817],[0.308788389],[0.4373158216],[0.5686125159],[0.7057172656]],\"88\":[[0.1683342755],[0.1097489595],[0.1308481246],[0.138541773],[0.1113670468],[0.1436378211],[0.1136104167],[0.1649060994],[0.1049672291],[0.3330059946],[0.0769060552],[0.0493293591],[0.0572365858],[0.0694779754],[0.0268358756],[0.0691422001],[0.0913430974]],\"89\":[[0.7078732252],[0.6988215446],[0.6090897918],[0.7911816239],[0.036434602],[0.7667249441],[0.7013252378],[0.7804723978],[0.6123002172],[0.7759528756],[0.7216721773],[0.7554674149],[0.7790154219],[0.8407734632],[0.6824557781],[0.786735177],[0.8161489964]],\"90\":[[0.1377263069],[0.1255222112],[0.2021134347],[0.1652851701],[0.076481536],[0.1455465704],[0.1890395731],[0.0961559787],[0.1031908318],[0.2358889133],[0.099086374],[0.0947460458],[0.1413204819],[0.227282986],[0.07962621],[0.1445330828],[0.0718203112]],\"91\":[[0.0197629146],[0.0104451776],[0.0199917909],[0.0080108158],[0.4364168644],[0.126173988],[0.320723325],[0.0295257326],[0.054132089],[0.0040471894],[0.0056699021],[0.0014625521],[0.0027360283],[0.0038431757],[0.0014322128],[0.0062889615],[0.0026616091]],\"92\":[[0.0131478524],[0.0131070204],[0.0157404989],[0.8397715688],[0.6646603346],[0.798397243],[0.8701730371],[0.8094670773],[0.7784590721],[0.0812170953],[0.0555945002],[0.5497431159],[0.541031003],[0.2199793309],[0.4084342122],[0.6768042445],[0.3907456696]],\"93\":[[0.6646633148],[0.7102746964],[0.6398393512],[0.7500140071],[0.0349902697],[0.7422248721],[0.6588490605],[0.8112007976],[0.2765376866],[0.7655826211],[0.1407932639],[0.6251420975],[0.5563744903],[0.6678094268],[0.680483222],[0.7370773554],[0.8167043328]],\"94\":[[0.3129821122],[0.3229204118],[0.3683968186],[0.3835482299],[0.1998068243],[0.3451819718],[0.4648948908],[0.4269743264],[0.4211249053],[0.4052115381],[0.3112808168],[0.3971903026],[0.378330946],[0.6263426542],[0.3478873074],[0.7074421644],[0.2708735168]],\"95\":[[0.2836553156],[0.3256038725],[0.3361012936],[0.1886037737],[0.2638720572],[0.1987431049],[0.2036195248],[0.1584860235],[0.1919961721],[0.0930691659],[0.2737777531],[0.2562532425],[0.2794396877],[0.3133246601],[0.4040609598],[0.3705023229],[0.4149440527]],\"96\":[[0.5015698075],[0.5383573771],[0.6070287824],[0.588843286],[0.4376164377],[0.5800847411],[0.5578144193],[0.6440612674],[0.4375756383],[0.5729376078],[0.4049507678],[0.3916824162],[0.4899439514],[0.5390657187],[0.5675731897],[0.3576243222],[0.6988428831]],\"97\":[[0.7811940908],[0.8139469624],[0.8688408136],[0.5362589359],[0.2689647675],[0.7262071967],[0.6344915032],[0.6109426022],[0.6918941736],[0.6506278515],[0.7775204778],[0.6392469406],[0.5894597173],[0.5893263221],[0.8554432392],[0.7386475801],[0.780833602]],\"98\":[[0.8211824894],[0.8732805848],[0.8451272249],[0.1799517125],[0.6934303045],[0.6771760583],[0.6562064886],[0.5503593087],[0.2436694503],[0.6577700973],[0.2959932685],[0.6244738102],[0.6264640093],[0.6801866293],[0.7456214428],[0.6463614106],[0.5349350572]],\"99\":[[0.3544616997],[0.3450897038],[0.3864521086],[0.2481504232],[0.5077797174],[0.450953871],[0.3829941154],[0.0775048509],[0.260881424],[0.1436223239],[0.2709293067],[0.103724964],[0.175044626],[0.0484917201],[0.1040663049],[0.0712901279],[0.2261613607]]},\"position\":{\"0\":[-0.079888957,-1.3431437165],\"1\":[-0.8217262415,-1.9554725056],\"2\":[1.264610971,1.8743114449],\"3\":[-0.5381903208,8.6627181043],\"4\":[-2.6566999201,8.6922341126],\"5\":[-1.7195830018,8.3901725241],\"6\":[0.9266840138,-1.9603182527],\"7\":[1.3422205182,13.6538288986],\"8\":[-0.8445374954,-2.6822540712],\"9\":[-0.196972957,-0.9753715463],\"10\":[0.8917834118,-2.7083372449],\"11\":[-0.6849709425,7.2280172137],\"12\":[1.3152370855,1.5097249393],\"13\":[-1.7536156816,7.1905288011],\"14\":[1.3269651265,11.0905623158],\"15\":[-2.7136622009,8.2378505427],\"16\":[0.5531717684,12.7258787202],\"17\":[-0.7356112296,-2.7109999827],\"18\":[-0.7691034961,5.5262913379],\"19\":[-0.3096644949,-0.3979614832],\"20\":[-1.6377053631,5.0467783581],\"21\":[1.0486957991,-1.7275761679],\"22\":[1.3320750923,8.9577738615],\"23\":[0.4737355334,9.887467487],\"24\":[1.1241125238,0.7672255339],\"25\":[-2.3878899318,5.9511790017],\"26\":[-0.5378666012,9.2303720708],\"27\":[-0.3862872262,-0.0179526933],\"28\":[0.9648467318,0.1985978014],\"29\":[-0.9948291945,-1.5134802692],\"30\":[0.8900824812,-2.0724270359],\"31\":[-1.944555785,4.0041475553],\"32\":[-0.8456046796,3.9126295737],\"33\":[-1.5826144171,3.826309514],\"34\":[1.2665768374,6.548565405],\"35\":[-0.5272664083,6.5639737836],\"36\":[0.3003720233,6.8628330672],\"37\":[-0.5075686953,0.6927841154],\"38\":[-0.9472360836,-2.4107638602],\"39\":[-1.0044568244,3.1992614633],\"40\":[0.9877120422,-0.0671076579],\"41\":[1.1042548382,5.198544352],\"42\":[-1.7551662468,3.172933237],\"43\":[-2.2282763686,3.5127769238],\"44\":[-0.5310329717,5.494599928],\"45\":[0.7628884289,-2.7019731136],\"46\":[0.2242027671,5.2082259465],\"47\":[0.8795204948,-0.5740944279],\"48\":[-0.8090352032,-2.0906726357],\"49\":[-0.5212424265,0.9116687174],\"50\":[-2.129582615,2.474799933],\"51\":[0.9230996825,4.0785646491],\"52\":[0.207651906,4.2940859336],\"53\":[-0.446116122,4.0468307828],\"54\":[-1.7778727546,2.6192774005],\"55\":[-1.059421174,2.5040596541],\"56\":[-1.1793448286,2.2450115713],\"57\":[0.7984348866,-0.9335417905],\"58\":[-1.7570106063,2.0104419336],\"59\":[0.8341732227,3.4464068526],\"60\":[0.2293076184,3.9397255686],\"61\":[-0.5656793796,1.4499084066],\"62\":[-0.3604316613,-1.9451895212],\"63\":[-2.0151188812,1.8359274289],\"64\":[-0.3837335766,3.6274997659],\"65\":[0.2523923188,3.1381932375],\"66\":[-0.2680989551,3.1381932375],\"67\":[-1.2320868346,1.7824057422],\"68\":[-0.614563658,1.9233879344],\"69\":[0.7572488732,3.002364716],\"70\":[0.6734349196,-1.1861413044],\"71\":[-2.2262669448,1.8681370384],\"72\":[-1.7875333523,1.4072108006],\"73\":[-0.194722617,-2.3877943995],\"74\":[0.6558711661,2.4132916292],\"75\":[-0.7629728043,2.2402901923],\"76\":[-1.3463321378,1.6506620922],\"77\":[-0.1986627028,2.7532838393],\"78\":[0.4161262295,-1.5540797081],\"79\":[-1.8611532541,0.9600402391],\"80\":[0.2291891601,2.4773466908],\"81\":[-2.2606518525,1.1369339756],\"82\":[0.198745447,-2.6602066701],\"83\":[-0.8646870097,2.8972884808],\"84\":[0.2732846954,2.2343134084],\"85\":[-0.2653604431,2.2383599485],\"86\":[0.1472571601,-2.110774713],\"87\":[-1.4372825052,1.3446261747],\"88\":[0.5146924865,1.8962205881],\"89\":[-1.879108646,0.7765901799],\"90\":[-2.2406684292,1.0273503431],\"91\":[0.1358281436,-2.8425946589],\"92\":[-0.9622180692,3.5213248718],\"93\":[-1.5445754233,1.3890835851],\"94\":[-0.3825477219,1.8985122689],\"95\":[-2.2851909622,0.5106033883],\"96\":[0.6141234713,1.4540506264],\"97\":[-0.0317367693,-2.255607379],\"98\":[-1.8235871572,0.6139322867],\"99\":[0.29084014,1.85425237]},\"in_cluster\":{\"0\":1,\"1\":1,\"2\":0,\"3\":0,\"4\":1,\"5\":1,\"6\":0,\"7\":0,\"8\":0,\"9\":0,\"10\":0,\"11\":0,\"12\":0,\"13\":0,\"14\":0,\"15\":0,\"16\":0,\"17\":0,\"18\":1,\"19\":0,\"20\":1,\"21\":0,\"22\":0,\"23\":0,\"24\":0,\"25\":0,\"26\":0,\"27\":0,\"28\":0,\"29\":0,\"30\":0,\"31\":1,\"32\":1,\"33\":1,\"34\":0,\"35\":1,\"36\":1,\"37\":0,\"38\":0,\"39\":1,\"40\":0,\"41\":1,\"42\":1,\"43\":1,\"44\":1,\"45\":0,\"46\":1,\"47\":0,\"48\":0,\"49\":0,\"50\":1,\"51\":1,\"52\":1,\"53\":1,\"54\":1,\"55\":1,\"56\":1,\"57\":0,\"58\":1,\"59\":1,\"60\":1,\"61\":0,\"62\":0,\"63\":1,\"64\":1,\"65\":1,\"66\":1,\"67\":1,\"68\":1,\"69\":1,\"70\":0,\"71\":1,\"72\":1,\"73\":0,\"74\":1,\"75\":1,\"76\":1,\"77\":1,\"78\":0,\"79\":1,\"80\":1,\"81\":1,\"82\":0,\"83\":1,\"84\":1,\"85\":1,\"86\":1,\"87\":1,\"88\":1,\"89\":1,\"90\":1,\"91\":1,\"92\":0,\"93\":1,\"94\":1,\"95\":1,\"96\":1,\"97\":0,\"98\":1,\"99\":1},\"respect_social_distancing\":{\"0\":0,\"1\":0,\"2\":1,\"3\":0,\"4\":0,\"5\":0,\"6\":0,\"7\":1,\"8\":0,\"9\":0,\"10\":0,\"11\":0,\"12\":1,\"13\":0,\"14\":0,\"15\":0,\"16\":0,\"17\":1,\"18\":0,\"19\":0,\"20\":0,\"21\":0,\"22\":0,\"23\":0,\"24\":0,\"25\":0,\"26\":0,\"27\":0,\"28\":0,\"29\":0,\"30\":0,\"31\":0,\"32\":0,\"33\":0,\"34\":0,\"35\":0,\"36\":0,\"37\":0,\"38\":0,\"39\":0,\"40\":0,\"41\":0,\"42\":0,\"43\":0,\"44\":0,\"45\":0,\"46\":0,\"47\":1,\"48\":1,\"49\":0,\"50\":0,\"51\":0,\"52\":0,\"53\":0,\"54\":0,\"55\":0,\"56\":0,\"57\":0,\"58\":0,\"59\":0,\"60\":0,\"61\":0,\"62\":0,\"63\":0,\"64\":0,\"65\":0,\"66\":0,\"67\":0,\"68\":0,\"69\":0,\"70\":0,\"71\":0,\"72\":0,\"73\":0,\"74\":0,\"75\":0,\"76\":0,\"77\":0,\"78\":0,\"79\":0,\"80\":0,\"81\":0,\"82\":0,\"83\":0,\"84\":0,\"85\":0,\"86\":0,\"87\":0,\"88\":0,\"89\":0,\"90\":0,\"91\":0,\"92\":0,\"93\":0,\"94\":0,\"95\":0,\"96\":0,\"97\":1,\"98\":0,\"99\":0},\"mask_preds\":{\"0\":0,\"1\":1,\"2\":0,\"3\":0,\"4\":0,\"5\":0,\"6\":1,\"7\":0,\"8\":1,\"9\":0,\"10\":1,\"11\":1,\"12\":0,\"13\":1,\"14\":0,\"15\":0,\"16\":0,\"17\":1,\"18\":1,\"19\":0,\"20\":0,\"21\":1,\"22\":0,\"23\":0,\"24\":0,\"25\":1,\"26\":1,\"27\":0,\"28\":0,\"29\":1,\"30\":1,\"31\":1,\"32\":1,\"33\":0,\"34\":0,\"35\":1,\"36\":0,\"37\":1,\"38\":1,\"39\":1,\"40\":0,\"41\":0,\"42\":1,\"43\":1,\"44\":1,\"45\":1,\"46\":0,\"47\":0,\"48\":1,\"49\":1,\"50\":1,\"51\":1,\"52\":0,\"53\":0,\"54\":1,\"55\":1,\"56\":1,\"57\":0,\"58\":1,\"59\":1,\"60\":1,\"61\":0,\"62\":1,\"63\":1,\"64\":0,\"65\":1,\"66\":1,\"67\":0,\"68\":0,\"69\":1,\"70\":0,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":0,\"76\":0,\"77\":0,\"78\":0,\"79\":0,\"80\":1,\"81\":0,\"82\":1,\"83\":0,\"84\":0,\"85\":1,\"86\":0,\"87\":0,\"88\":1,\"89\":1,\"90\":1,\"91\":0,\"92\":0,\"93\":1,\"94\":1,\"95\":1,\"96\":1,\"97\":0,\"98\":1,\"99\":0},\"mask_pred_probs\":{\"0\":[0.8557123542,0.1442876607],\"1\":[0.158796221,0.8412038088],\"2\":[0.8565556407,0.1434443891],\"3\":[0.8367882967,0.1632116288],\"4\":[0.8003365397,0.1996634454],\"5\":[0.544300437,0.4556995332],\"6\":[0.0272116624,0.9727883935],\"7\":[0.8238860369,0.1761139482],\"8\":[0.1187053025,0.8812947273],\"9\":[0.8330813646,0.1669185609],\"10\":[0.0311512295,0.9688488245],\"11\":[0.0018414977,0.9981585145],\"12\":[0.9380007982,0.0619992204],\"13\":[0.4607952237,0.5392047763],\"14\":[0.9271683097,0.0728316903],\"15\":[0.8175127506,0.1824872047],\"16\":[0.865503788,0.1344962567],\"17\":[0.160406813,0.8395931721],\"18\":[0.0030877835,0.996912241],\"19\":[0.7079702616,0.2920297682],\"20\":[0.8315048814,0.1684951186],\"21\":[0.0014292023,0.9985707998],\"22\":[0.6314004064,0.3685996532],\"23\":[0.6327915192,0.367208451],\"24\":[0.8767199516,0.123280108],\"25\":[0.0530023314,0.9469977021],\"26\":[0.0550887994,0.9449111819],\"27\":[0.5790531635,0.4209467769],\"28\":[0.9439992905,0.0560007431],\"29\":[0.0227953643,0.9772046208],\"30\":[0.0055171093,0.9944828749],\"31\":[0.0076579675,0.9923420548],\"32\":[0.0808878243,0.9191121459],\"33\":[0.7142472267,0.2857528031],\"34\":[0.6794006824,0.3205992579],\"35\":[0.0520888939,0.9479111433],\"36\":[0.5449418426,0.4550581574],\"37\":[0.3494385481,0.6505613923],\"38\":[0.0137012918,0.9862987399],\"39\":[0.1677199453,0.8322800398],\"40\":[0.6264102459,0.3735897839],\"41\":[0.8201075792,0.1798924506],\"42\":[0.2967045605,0.7032954693],\"43\":[0.0012809634,0.9987190962],\"44\":[0.1917557567,0.808244288],\"45\":[0.0154695353,0.9845304489],\"46\":[0.7860686183,0.2139313966],\"47\":[0.7767740488,0.223225981],\"48\":[0.0896530896,0.9103468657],\"49\":[0.3778083622,0.6221916676],\"50\":[0.0003134598,0.9996865988],\"51\":[0.1133278385,0.8866721392],\"52\":[0.5570104122,0.442989558],\"53\":[0.7057663798,0.2942335904],\"54\":[0.3571150303,0.6428849101],\"55\":[0.3815810978,0.618418932],\"56\":[0.3517460227,0.6482540369],\"57\":[0.9335421324,0.0664578229],\"58\":[0.4702195823,0.5297804475],\"59\":[0.0647930801,0.9352069497],\"60\":[0.0164399557,0.9835600853],\"61\":[0.7315810323,0.2684189677],\"62\":[0.0588309206,0.9411690831],\"63\":[0.2401295602,0.7598704696],\"64\":[0.5378111005,0.4621888101],\"65\":[0.0287833624,0.9712166786],\"66\":[0.3456963599,0.6543036103],\"67\":[0.6413789988,0.3586210012],\"68\":[0.8836128116,0.1163872182],\"69\":[0.074080117,0.9259198308],\"70\":[0.940895021,0.059104953],\"71\":[0.0008888248,0.9991111159],\"72\":[0.2230629772,0.7769370675],\"73\":[0.0215474162,0.9784526229],\"74\":[0.2966458201,0.7033541799],\"75\":[0.858353734,0.1416462511],\"76\":[0.5648492575,0.4351507127],\"77\":[0.5442197919,0.4557802379],\"78\":[0.9471672773,0.0528327525],\"79\":[0.6094569564,0.3905430734],\"80\":[0.4695384204,0.5304615498],\"81\":[0.7415559292,0.258444041],\"82\":[0.0349928811,0.9650071263],\"83\":[0.9161883593,0.0838116258],\"84\":[0.662419498,0.3375805318],\"85\":[0.4197466373,0.5802533627],\"86\":[0.9130544066,0.0869455487],\"87\":[0.5796843171,0.4203156829],\"88\":[0.231738627,0.7682614326],\"89\":[0.1595934182,0.8404065371],\"90\":[0.0257942677,0.9742057323],\"91\":[0.6015203595,0.3984796107],\"92\":[0.7245189548,0.275481075],\"93\":[0.0060548894,0.9939450622],\"94\":[0.2652786672,0.734721303],\"95\":[0.0008094235,0.9991906285],\"96\":[0.2089118212,0.7910881639],\"97\":[0.8916653991,0.1083345562],\"98\":[0.3358977139,0.6641022563],\"99\":[0.5165854692,0.483414501]},\"mask_head_regions\":{\"0\":[472,162,56,56],\"1\":[350,223,69,69],\"2\":[584,52,41,41],\"3\":[473,24,29,29],\"4\":[399,53,29,29],\"5\":[434,33,27,27],\"6\":[631,252,52,52],\"7\":[533,11,35,35],\"8\":[345,254,74,74],\"9\":[466,136,52,52],\"10\":[631,292,51,51],\"11\":[464,0,33,33],\"12\":[588,68,41,41],\"13\":[419,7,34,34],\"14\":[540,3,25,25],\"15\":[396,43,31,31],\"16\":[522,14,20,20],\"17\":[353,281,79,79],\"18\":[454,0,36,36],\"19\":[457,132,46,46],\"20\":[406,0,35,35],\"21\":[612,326,68,68],\"22\":[551,43,17,17],\"23\":[525,43,6,6],\"24\":[585,80,46,46],\"25\":[380,0,36,36],\"26\":[467,13,36,36],\"27\":[446,95,56,56],\"28\":[577,91,50,50],\"29\":[351,315,74,74],\"30\":[619,388,56,56],\"31\":[367,0,45,45],\"32\":[441,4,36,36],\"33\":[397,2,39,39],\"34\":[551,31,31,31],\"35\":[454,4,36,36],\"36\":[511,44,29,29],\"37\":[446,114,53,53],\"38\":[354,320,85,85],\"39\":[423,11,37,37],\"40\":[578,107,52,52],\"41\":[553,0,37,37],\"42\":[380,11,38,38],\"43\":[358,0,39,39],\"44\":[466,40,36,36],\"45\":[603,428,59,59],\"46\":[510,0,35,35],\"47\":[578,126,49,49],\"48\":[390,353,72,72],\"49\":[445,59,42,42],\"50\":[344,5,39,39],\"51\":[546,0,38,38],\"52\":[506,17,37,37],\"53\":[465,26,37,37],\"54\":[370,24,39,39],\"55\":[413,21,40,40],\"56\":[404,34,36,36],\"57\":[573,148,49,49],\"58\":[357,36,38,38],\"59\":[545,0,39,39],\"60\":[506,0,40,40],\"61\":[448,48,40,40],\"62\":[437,357,61,61],\"63\":[329,15,47,47],\"64\":[471,0,38,38],\"65\":[511,3,40,40],\"66\":[473,3,39,39],\"67\":[392,45,39,39],\"68\":[445,40,41,41],\"69\":[545,12,40,40],\"70\":[560,169,52,52],\"71\":[323,32,42,42],\"72\":[346,50,39,39],\"73\":[465,388,58,58],\"74\":[527,15,51,51],\"75\":[433,31,40,40],\"76\":[386,75,38,38],\"77\":[479,20,40,40],\"78\":[529,192,55,55],\"79\":[335,69,38,38],\"80\":[509,20,42,42],\"81\":[315,82,27,27],\"82\":[504,407,74,74],\"83\":[435,20,34,34],\"84\":[514,30,37,37],\"85\":[472,28,41,41],\"86\":[506,214,61,61],\"87\":[379,69,30,30],\"88\":[530,26,47,47],\"89\":[323,69,48,48],\"90\":[299,65,47,47],\"91\":[546,426,61,61],\"92\":[423,0,49,49],\"93\":[360,57,40,40],\"94\":[459,26,47,47],\"95\":[287,65,49,49],\"96\":[540,45,45,45],\"97\":[482,234,62,62],\"98\":[338,76,39,39],\"99\":[513,28,49,49]}}\n"
          ]
        }
      ],
      "source": [
        "print(person_json_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBD2e1Kt24pr"
      },
      "source": [
        "These JSON strings can now be packaged and sent to an API (or any desired location) as required.\n",
        "\n",
        "When received by our API, the results can easily be decoded and read again into pandas, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcegcQ_J24pr",
        "outputId": "7cfef395-651d-4e73-d84d-5162296a063b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>person_count</th>\n",
              "      <th>clusters_count</th>\n",
              "      <th>social_distancing_compliance</th>\n",
              "      <th>mask_proportions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_12</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_25</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_37</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_50</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id  person_count  clusters_count  social_distancing_compliance  \\\n",
              "0   frame_0             8               2                      0.250000   \n",
              "1  frame_12             9               0                      0.111111   \n",
              "2  frame_25            10               1                      0.100000   \n",
              "3  frame_37            10               2                      0.000000   \n",
              "4  frame_50            10               2                      0.000000   \n",
              "\n",
              "   mask_proportions  \n",
              "0          0.250000  \n",
              "1          0.444444  \n",
              "2          0.500000  \n",
              "3          0.500000  \n",
              "4          0.700000  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "received_frame_results = pd.read_json(frame_json_results)\n",
        "received_frame_results.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfds7w2u24pr",
        "outputId": "d2c061d2-1192-42d1-f4f0-c645b72c5130"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>bbox</th>\n",
              "      <th>keypoints</th>\n",
              "      <th>confidences</th>\n",
              "      <th>position</th>\n",
              "      <th>in_cluster</th>\n",
              "      <th>respect_social_distancing</th>\n",
              "      <th>mask_preds</th>\n",
              "      <th>mask_pred_probs</th>\n",
              "      <th>mask_head_regions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[456.0, 143.0, 550.0, 385.0]</td>\n",
              "      <td>[[497.125, 192.15625], [497.125, 192.15625], [...</td>\n",
              "      <td>[[0.0150153972], [0.0166315492], [0.0142668430...</td>\n",
              "      <td>[-0.07988895700000001, -1.3431437165]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8557123542, 0.14428766070000001]</td>\n",
              "      <td>[472, 162, 56, 56]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[340.0, 202.0, 438.0, 484.0]</td>\n",
              "      <td>[[386.9583435059, 263.6875], [386.9583435059, ...</td>\n",
              "      <td>[[0.5421698689000001], [0.4973727167], [0.5392...</td>\n",
              "      <td>[-0.8217262415000001, -1.9554725056]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.15879622100000002, 0.8412038088]</td>\n",
              "      <td>[350, 223, 69, 69]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[570.0, 40.0, 638.0, 203.0]</td>\n",
              "      <td>[[605.4166870117, 75.65625], [606.8333129883, ...</td>\n",
              "      <td>[[0.8332034945000001], [0.9014892578], [0.8185...</td>\n",
              "      <td>[1.264610971, 1.8743114449]</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8565556407, 0.1434443891]</td>\n",
              "      <td>[584, 52, 41, 41]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[469.0, 0.0, 514.0, 96.0]</td>\n",
              "      <td>[[496.1875, 1.5], [484.0, 34.5], [477.4375, 31...</td>\n",
              "      <td>[[0.0048622992000000005], [0.00185993720000000...</td>\n",
              "      <td>[-0.5381903208000001, 8.6627181043]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8367882967, 0.1632116288]</td>\n",
              "      <td>[473, 24, 29, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame_0</td>\n",
              "      <td>[386.0, 0.0, 429.0, 86.0]</td>\n",
              "      <td>[[405.7083435059, 73.90625], [420.0416564941, ...</td>\n",
              "      <td>[[0.0012897616000000002], [0.0018837501], [0.0...</td>\n",
              "      <td>[-2.6566999201, 8.6922341126]</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.8003365397000001, 0.1996634454]</td>\n",
              "      <td>[399, 53, 29, 29]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id                          bbox  \\\n",
              "0  frame_0  [456.0, 143.0, 550.0, 385.0]   \n",
              "1  frame_0  [340.0, 202.0, 438.0, 484.0]   \n",
              "2  frame_0   [570.0, 40.0, 638.0, 203.0]   \n",
              "3  frame_0     [469.0, 0.0, 514.0, 96.0]   \n",
              "4  frame_0     [386.0, 0.0, 429.0, 86.0]   \n",
              "\n",
              "                                           keypoints  \\\n",
              "0  [[497.125, 192.15625], [497.125, 192.15625], [...   \n",
              "1  [[386.9583435059, 263.6875], [386.9583435059, ...   \n",
              "2  [[605.4166870117, 75.65625], [606.8333129883, ...   \n",
              "3  [[496.1875, 1.5], [484.0, 34.5], [477.4375, 31...   \n",
              "4  [[405.7083435059, 73.90625], [420.0416564941, ...   \n",
              "\n",
              "                                         confidences  \\\n",
              "0  [[0.0150153972], [0.0166315492], [0.0142668430...   \n",
              "1  [[0.5421698689000001], [0.4973727167], [0.5392...   \n",
              "2  [[0.8332034945000001], [0.9014892578], [0.8185...   \n",
              "3  [[0.0048622992000000005], [0.00185993720000000...   \n",
              "4  [[0.0012897616000000002], [0.0018837501], [0.0...   \n",
              "\n",
              "                                position  in_cluster  \\\n",
              "0  [-0.07988895700000001, -1.3431437165]           1   \n",
              "1   [-0.8217262415000001, -1.9554725056]           1   \n",
              "2            [1.264610971, 1.8743114449]           0   \n",
              "3    [-0.5381903208000001, 8.6627181043]           0   \n",
              "4          [-2.6566999201, 8.6922341126]           1   \n",
              "\n",
              "   respect_social_distancing  mask_preds                      mask_pred_probs  \\\n",
              "0                          0           0  [0.8557123542, 0.14428766070000001]   \n",
              "1                          0           1  [0.15879622100000002, 0.8412038088]   \n",
              "2                          1           0         [0.8565556407, 0.1434443891]   \n",
              "3                          0           0         [0.8367882967, 0.1632116288]   \n",
              "4                          0           0   [0.8003365397000001, 0.1996634454]   \n",
              "\n",
              "    mask_head_regions  \n",
              "0  [472, 162, 56, 56]  \n",
              "1  [350, 223, 69, 69]  \n",
              "2   [584, 52, 41, 41]  \n",
              "3   [473, 24, 29, 29]  \n",
              "4   [399, 53, 29, 29]  "
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "received_person_results = pd.read_json(person_json_results)\n",
        "received_person_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ5Qillx24pr"
      },
      "source": [
        "## Experimentation with weights and density heatmap generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLtulDvG24pr"
      },
      "source": [
        "We'll be plotting a density heatmap using a weighted Kernel Density Estimation (KDE) model, with a Gaussian-based kernel, defined as follows:\n",
        "\n",
        "$ p(\\textbf{x} | D ) = \\displaystyle\\frac{1}{N}\\sum_{n=1}^{N} \\alpha_{risk} K_{h} (\\textbf{x} - \\textbf{x}_{n}) $\n",
        "\n",
        "Where $ K_{h} $ is a Gaussian kernel, defined as follows:\n",
        "\n",
        "$ K_{h}(\\textbf{x}) = \\displaystyle\\frac{1}{h^{D}(2\\pi)^{D/2}} \\prod_{d = 1}^{D} exp(- \\frac{1}{2h^{2}} x_{d}^{2} ) $\n",
        "\n",
        "Where $ h $ is a bandwidth parameter that represents the width of our kernel.\n",
        "\n",
        "In addition, the weight $ \\alpha_{risk} $ for each data sample is determined using the risk-based factors extracted for each person in the scene from our downstream models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAGayTmb24ps"
      },
      "outputs": [],
      "source": [
        "frame_mask = received_person_results['image_id'] == 'frame_12'\n",
        "frame_df = received_person_results.loc[frame_mask].copy()\n",
        "frame_posns = np.stack(frame_df['position'].apply(np.array).values, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaQwTD_o24ps",
        "outputId": "f167b0a0-48bb-4e09-c481-7dcea5ccb9a8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "has_mask = frame_df['mask_preds'] == 1\n",
        "is_safe_dist =  frame_df['respect_social_distancing'] == 1\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(x=frame_posns[has_mask, 0], y=frame_posns[has_mask, 1], \n",
        "            color=\"tab:green\", label=\"Mask On\")\n",
        "plt.scatter(x=frame_posns[~has_mask, 0], y=frame_posns[~has_mask, 1], \n",
        "            color=\"tab:red\", label=\"No Mask\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEMO0_FT24ps"
      },
      "source": [
        "Lets simulate some weights, by making those people without masks a risk, whilst those with are safe. We can then plot a heatmap showing the locations of all those without a mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZPYeusT24ps",
        "outputId": "bb052e52-65dd-4e3a-d8e1-c134464bd7e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# determine weights using sum of wearing mask and whether they're violating distance\n",
        "weights = 1 - frame_df['mask_preds'].values\n",
        "weights = weights + (1 - frame_df['respect_social_distancing'])\n",
        "\n",
        "# plot heatmap of risk based on weights formed above\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.kdeplot(x=frame_posns[:, 0], y=frame_posns[:, 1], shade=True, \n",
        "            bw_adjust=0.5, cmap=\"Reds\", weights=weights, alpha=0.95)\n",
        "plt.scatter(x=frame_posns[has_mask, 0], y=frame_posns[has_mask, 1], \n",
        "            color=\"tab:green\", label=\"Mask On\", s=100)\n",
        "plt.scatter(x=frame_posns[~has_mask, 0], y=frame_posns[~has_mask, 1], \n",
        "            color=\"tab:red\", label=\"No Mask\", s=100)\n",
        "plt.title(\"Risk Density Heatmap - Social Distancing\", weight=\"bold\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3NI6x2X24ps"
      },
      "source": [
        "As shown, the heatmap shows areas where people aren't wearing masks and are in close-proximity as more dangerous, whilst those areas where people are social distancing with masks are much lower risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh78eTqG24pt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AlphaPose_Downstream_Modelling_Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}